{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilayer neural networks are a current hot-topic in machine learning. The multilayer perceptron was the first standardized architecture.  In this assignment, you will learn to tune a [multilayer perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron) model.\n",
    "\n",
    "There are many libraries for using neural networks, but there isn't yet a single standard.  [Tensorflow](https://www.tensorflow.org/) is used by many, with [Keras](https://keras.io/) as one of the official APIs.\n",
    "\n",
    "\n",
    "## Part 1: Installation, and Introduction to Keras\n",
    "\n",
    "We'll be installing Keras and Tensorflow using a Docker container.  You could install Tensorflow natively (see [here](https://www.tensorflow.org/install/pip)) but Tensforflow typically causes downgrades in the Anaconda environment, and it has screwed up students'  Anaconda distribution in the past.\n",
    "\n",
    "**NOTE** If you have a PC with an NVIDIA GPU, and you want to train on it (highly recommended if you're pursuing a neural-net based capstone project), then you'll want to install `nvidia-docker` instead.  Go to the end of this assignment (the bottom of this page) and follow the install directions there.\n",
    "\n",
    "So, on with the Docker install:\n",
    "* Go to the home directory in your Terminal.  \n",
    "  ```bash\n",
    "  $ cd ~\n",
    "  ```\n",
    "\n",
    "* Start a Jupyter server on a `Docker` instance with Tensorflow 2.0 installed. This will pull the image from Docker Hub and make a container named `tensorflow`.\n",
    "\n",
    "    ```bash\n",
    "    $ docker run -it --name tensorflow -p 8888:8888 -v \"$PWD\":/tf tensorflow/tensorflow:2.0.0a0-py3-jupyter\n",
    "    ```\n",
    "  * After starting up the `docker` container and running the `Jupyter` notebook, you'll see a printout like:\n",
    "    ```\n",
    "    ...\n",
    "    To access the notebook, open this file in a browser:\n",
    "        file:///root/.local/share/jupyter/runtime/nbserver-10-open.html\n",
    "    Or copy and paste one of these URLs:\n",
    "        http://(ae4038ed94a3 or 127.0.0.1):8888/?token=e305929f1dca3ae69707f9a67d6467bd92ce3c1d6521919c\n",
    "    ```\n",
    "    \n",
    "    The hex number after `token=` is a password you need to access the notebook. In this case, it is `e305929f1dca3ae69707f9a67d6467bd92ce3c1d6521919c`, but yours will be different.\n",
    "  * Go to `http://localhost:8888` and enter in the password when prompted.\n",
    "  * If you use the above Docker command, the working directory will map to directory `/tf` in the container. The working directory of the Jupyter notebook in the container is `/tf`, and a useful Python script for this assignment in the `src` directory of this repository. Make sure that the `src` directory is in the Jupyter notebook's Python path, one way or another.\n",
    "\n",
    "* This Docker image (and the resulting container) has `numpy`, `keras`, and `tensorflow` packages.  However, it's lacking `pandas` and `sklearn`.  If you want to use them in this assignment, you'll have to access the container from the command line to install them.  Here's how you do that.  \n",
    "  ```bash\n",
    "  $ docker exec -it tensorflow /bin/bash\n",
    "  ```\n",
    "  Then from within the container:\n",
    "  ```bash\n",
    "  # pip install -U scikit-learn  \n",
    "  # pip install pandas\n",
    "  ```\n",
    "* For this assignment you have a couple of workflow options.  You could work in the Jupyter notebook.  Or, you can access the Tensorflow container from Terminal (as you did above) so that you can run a script from the command line.  To do this, in your Terminal access the running container in the bash shell using:  \n",
    "    ```bash\n",
    "    $ docker exec -it tensorflow /bin/bash\n",
    "    ```\n",
    "  Then from within the container:\n",
    "  ```bash\n",
    "  # python mlp.py\n",
    "  ```  \n",
    "  Or:\n",
    "  ```bash\n",
    "  # ipython\n",
    "  In [1]: run mlp.py\n",
    "  ```\n",
    "\n",
    "* Briefly read some example code for Multilayer Perceptron (the standard neural network) at http://keras.io/examples/. Note that these examples are out of date.  If you want to run the examples in the link, you need to import `keras` and supporting modules differently than what's shown in the examples.  Specifically, they need to be imported from `tensorflow`:\n",
    "\n",
    "    ```python\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "    from tensorflow.keras.optimizers import SGD\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Building and tuning a neural network model\n",
    "\n",
    "In the Docker-backed Jupyter notebook/Terminal/Ipython console, use the `load_and_condition_MNIST_data` function in `src/mlp.py` to load a train and test set of images of hand-drawn digits.\n",
    "\n",
    "### Initial inspection\n",
    "\n",
    "```python\n",
    "from mlp import load_and_condition_MNIST_data\n",
    "X_train, y_train, X_test, y_test, y_train_onehot = load_and_condition_MNIST_data()\n",
    "```\n",
    "\n",
    "1. The shape of `X_train` is (n_samples, n_features). How many samples are there in the training set? How many in the test set? How many features are there per sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n",
      "\n",
      "Loaded MNIST images\n",
      "\n",
      "First 5 labels of MNIST y_train: [5 0 4 1 9]\n",
      "\n",
      "First 5 labels of MNIST y_train (one-hot):\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.mlp import load_and_condition_MNIST_data\n",
    "X_train, y_train, X_test, y_test, y_train_onehot = load_and_condition_MNIST_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. You may have noticed that each sample \"image\" is a row from the `X` matrix - it's a 1-dimensional array. Speculate on why this is a convenient way to store images."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Because it allows us to know where the data is, change their shape, and put it into a NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Inspect a few of the sample images. (You may find the `np.reshape` and `ax.imshow` methods useful.) Inspect some of the corresponding labels from the labels `y_train`; you'll find that they're simply a number corresponding to the digit depicted in the image.\n",
    "\n",
    "Look at the `y_train_onehot` labels. What's going on there? We'll get to that soon.\n",
    "\n",
    "Our task is to use X_train and y_train to make a model that will accurately predict the labels in X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADoBJREFUeJzt3X2MXOV1x/HfyXq9jo1JvHHYboiLHeMEiGlMOjIgLKCiuA5CMiiKiRVFDiFxmuCktK4EdavGrWjlVgmRQynS0ri2I95CAsJ/0CR0FUGiwpbFMeYtvJlNY7PsYjZgQ4i9Xp/+sdfRBnaeWc/cmTu75/uRVjtzz71zj6792zszz8x9zN0FIJ53Fd0AgGIQfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQU1r5M6mW5vP0KxG7hII5bd6U4f9kE1k3ZrCb2YrJG2W1CLpP9x9U2r9GZqls+2iWnYJIKHHuye8btVP+82sRdJNkj4h6QxJq83sjGofD0Bj1fKaf6mk5919j7sflnSHpJX5tAWg3moJ/8mSfjXm/t5s2e8xs7Vm1mtmvcM6VMPuAOSp7u/2u3uXu5fcvdSqtnrvDsAE1RL+fZLmjbn/wWwZgEmglvA/ImmRmS0ws+mSPi1pRz5tAai3qof63P2Ima2T9CONDvVtcfcnc+sMQF3VNM7v7vdJui+nXgA0EB/vBYIi/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+IKiaZuk1sz5JByWNSDri7qU8mkJ+bFr6n7jl/XPruv9n/np+2drIzKPJbU9ZOJisz/yKJesv3zC9bG1n6c7ktvtH3kzWz75rfbJ+6l89nKw3g5rCn/kTd9+fw+MAaCCe9gNB1Rp+l/RjM3vUzNbm0RCAxqj1af8yd99nZidJut/MfuHuD45dIfujsFaSZmhmjbsDkJeazvzuvi/7PSjpHklLx1mny91L7l5qVVstuwOQo6rDb2azzGz2sduSlkt6Iq/GANRXLU/7OyTdY2bHHuc2d/9hLl0BqLuqw+/ueyR9LMdepqyW0xcl697Wmqy/dMF7k/W3zik/Jt3+nvR49U8/lh7vLtJ//WZ2sv4v/7YiWe8587aytReH30puu2ng4mT9Az/1ZH0yYKgPCIrwA0ERfiAowg8ERfiBoAg/EFQe3+oLb+TCjyfrN2y9KVn/cGv5r55OZcM+kqz//Y2fS9anvZkebjv3rnVla7P3HUlu27Y/PRQ4s7cnWZ8MOPMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM8+eg7ZmXkvVHfzsvWf9w60Ce7eRqff85yfqeN9KX/t668Ptla68fTY/Td3z7f5L1epr8X9itjDM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRl7o0b0TzR2v1su6hh+2sWQ1eem6wfWJG+vHbL7hOS9ce+cuNx93TM9fv/KFl/5IL0OP7Ia68n635u+au7930tuakWrH4svQLeoce7dcCH0nOXZzjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQFcf5zWyLpEslDbr74mxZu6Q7Jc2X1Cdplbv/utLOoo7zV9Iy933J+sirQ8n6i7eVH6t/8vwtyW2X/vNXk/WTbiruO/U4fnmP82+V9PaJ0K+T1O3uiyR1Z/cBTCIVw+/uD0p6+6lnpaRt2e1tki7LuS8AdVbta/4Od+/Pbr8sqSOnfgA0SM1v+PnomwZl3zgws7Vm1mtmvcM6VOvuAOSk2vAPmFmnJGW/B8ut6O5d7l5y91Kr2qrcHYC8VRv+HZLWZLfXSLo3n3YANErF8JvZ7ZIekvQRM9trZldJ2iTpYjN7TtKfZvcBTCIVr9vv7qvLlBiwz8nI/ldr2n74wPSqt/3oZ55K1l+5uSX9AEdHqt43isUn/ICgCD8QFOEHgiL8QFCEHwiK8ANBMUX3FHD6tc+WrV15ZnpE9j9P6U7WL/jU1cn67DsfTtbRvDjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQjPNPAalpsl/98unJbf9vx1vJ+nXXb0/W/2bV5cm6//w9ZWvz/umh5LZq4PTxEXHmB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgKk7RnSem6G4+Q58/N1m/9evfSNYXTJtR9b4/un1dsr7olv5k/cievqr3PVXlPUU3gCmI8ANBEX4gKMIPBEX4gaAIPxAU4QeCqjjOb2ZbJF0qadDdF2fLNkr6oqRXstU2uPt9lXbGOP/k4+ctSdZP3LQ3Wb/9Qz+qet+n/eQLyfpH/qH8dQwkaeS5PVXve7LKe5x/q6QV4yz/lrsvyX4qBh9Ac6kYfnd/UNJQA3oB0EC1vOZfZ2a7zWyLmc3JrSMADVFt+G+WtFDSEkn9kr5ZbkUzW2tmvWbWO6xDVe4OQN6qCr+7D7j7iLsflXSLpKWJdbvcveTupVa1VdsngJxVFX4z6xxz93JJT+TTDoBGqXjpbjO7XdKFkuaa2V5JX5d0oZktkeSS+iR9qY49AqgDvs+PmrR0nJSsv3TFqWVrPdduTm77rgpPTD/z4vJk/fVlrybrUxHf5wdQEeEHgiL8QFCEHwiK8ANBEX4gKIb6UJjv7U1P0T3Tpifrv/HDyfqlX72m/GPf05PcdrJiqA9ARYQfCIrwA0ERfiAowg8ERfiBoAg/EFTF7/MjtqPL0pfufuFT6Sm6Fy/pK1urNI5fyY1DZyXrM+/trenxpzrO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOP8U5yVFifrz34tPdZ+y3nbkvXzZ6S/U1+LQz6crD88tCD9AEf7c+xm6uHMDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBVRznN7N5krZL6pDkkrrcfbOZtUu6U9J8SX2SVrn7r+vXalzTFpySrL9w5QfK1jZecUdy20+esL+qnvKwYaCUrD+w+Zxkfc629HX/kTaRM/8RSevd/QxJ50i62szOkHSdpG53XySpO7sPYJKoGH5373f3ndntg5KelnSypJWSjn38a5uky+rVJID8HddrfjObL+ksST2SOtz92OcnX9boywIAk8SEw29mJ0j6gaRr3P3A2JqPTvg37qR/ZrbWzHrNrHdYh2pqFkB+JhR+M2vVaPBvdfe7s8UDZtaZ1TslDY63rbt3uXvJ3UutasujZwA5qBh+MzNJ35H0tLvfMKa0Q9Ka7PYaSffm3x6AepnIV3rPk/RZSY+b2a5s2QZJmyR9z8yukvRLSavq0+LkN23+Hybrr/9xZ7J+xT/+MFn/8/fenazX0/r+9HDcQ/9efjivfev/Jredc5ShvHqqGH53/5mkcvN9X5RvOwAahU/4AUERfiAowg8ERfiBoAg/EBThB4Li0t0TNK3zD8rWhrbMSm775QUPJOurZw9U1VMe1u1blqzvvDk9Rffc7z+RrLcfZKy+WXHmB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgwozzH/6z9GWiD//lULK+4dT7ytaWv/vNqnrKy8DIW2Vr5+9Yn9z2tL/7RbLe/lp6nP5osopmxpkfCIrwA0ERfiAowg8ERfiBoAg/EBThB4IKM87fd1n679yzZ95Vt33f9NrCZH3zA8uTdRspd+X0Uadd/2LZ2qKBnuS2I8kqpjLO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QlLl7egWzeZK2S+qQ5JK63H2zmW2U9EVJr2SrbnD38l96l3SitfvZxqzeQL30eLcO+FD6gyGZiXzI54ik9e6+08xmS3rUzO7Pat9y929U2yiA4lQMv7v3S+rPbh80s6clnVzvxgDU13G95jez+ZLOknTsM6PrzGy3mW0xszlltllrZr1m1jusQzU1CyA/Ew6/mZ0g6QeSrnH3A5JulrRQ0hKNPjP45njbuXuXu5fcvdSqthxaBpCHCYXfzFo1Gvxb3f1uSXL3AXcfcfejkm6RtLR+bQLIW8Xwm5lJ+o6kp939hjHLO8esdrmk9HStAJrKRN7tP0/SZyU9bma7smUbJK02syUaHf7rk/SlunQIoC4m8m7/zySNN26YHNMH0Nz4hB8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoipfuznVnZq9I+uWYRXMl7W9YA8enWXtr1r4keqtWnr2d4u7vn8iKDQ3/O3Zu1uvupcIaSGjW3pq1L4neqlVUbzztB4Ii/EBQRYe/q+D9pzRrb83al0Rv1Sqkt0Jf8wMoTtFnfgAFKST8ZrbCzJ4xs+fN7LoieijHzPrM7HEz22VmvQX3ssXMBs3siTHL2s3sfjN7Lvs97jRpBfW20cz2Zcdul5ldUlBv88zsJ2b2lJk9aWZ/kS0v9Ngl+irkuDX8ab+ZtUh6VtLFkvZKekTSand/qqGNlGFmfZJK7l74mLCZnS/pDUnb3X1xtuxfJQ25+6bsD+ccd7+2SXrbKOmNomduziaU6Rw7s7SkyyR9TgUeu0Rfq1TAcSvizL9U0vPuvsfdD0u6Q9LKAvpoeu7+oKShty1eKWlbdnubRv/zNFyZ3pqCu/e7+87s9kFJx2aWLvTYJfoqRBHhP1nSr8bc36vmmvLbJf3YzB41s7VFNzOOjmzadEl6WVJHkc2Mo+LMzY30tpmlm+bYVTPjdd54w++dlrn7xyV9QtLV2dPbpuSjr9maabhmQjM3N8o4M0v/TpHHrtoZr/NWRPj3SZo35v4Hs2VNwd33Zb8HJd2j5pt9eODYJKnZ78GC+/mdZpq5ebyZpdUEx66ZZrwuIvyPSFpkZgvMbLqkT0vaUUAf72Bms7I3YmRmsyQtV/PNPrxD0prs9hpJ9xbYy+9plpmby80srYKPXdPNeO3uDf+RdIlG3/F/QdLfFtFDmb4+JOmx7OfJonuTdLtGnwYOa/S9kaskvU9St6TnJP23pPYm6u27kh6XtFujQessqLdlGn1Kv1vSruznkqKPXaKvQo4bn/ADguINPyAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQf0/sEWOix6VKakAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(X_train[0].reshape(28,28));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model\n",
    "\n",
    "If we conceptualize each image sample as a 1-dimensional vector, we can use any multiclass model available. For example, we could simply train a single decision tree:\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "yhat = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, yhat))\n",
    "```\n",
    "\n",
    "If you run this, you'll find a single decision tree can classify hand-drawn digits with about 88% accuracy. Pretty good for being so simple. That's the score to beat.\n",
    "\n",
    "Take a moment to discuss with your partner what each split in the decision tree means, and what it means for a decision tree to classify an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "yhat = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Keras\n",
    "\n",
    "Maybe the simplest possible model in Keras a neural network with a single unit and no hidden layer:\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples, n_feats = X_train.shape\n",
    "\n",
    "model = Sequential() # sequence of layers\n",
    "\n",
    "denselayer = Dense(units=1,\n",
    "                input_dim=n_feats,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='sigmoid')\n",
    "\n",
    "model.add(denselayer)\n",
    "```\n",
    "\n",
    "1. Build this model, and **without training it**, use the `.predict(X_test)` method to predict the output label of the test set. What is the shape of the output of `predict`? Speculate about why this works, even if you haven't trained the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples, n_feats = X_train.shape\n",
    "\n",
    "model = Sequential() # sequence of layers\n",
    "\n",
    "denselayer = Dense(units=1,\n",
    "                input_dim=n_feats,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='sigmoid')\n",
    "\n",
    "model.add(denselayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model.predict(X_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "it's 10,000 because that is one value per input in X_test. but I the output was uniform but then got crunched into the sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The output of this model is the activation of a single \"neuron\" (aka \"unit\"), as a function of all 784 input pixel features. The output of the neuron is `activation_function( m*x+b )`, where `activation_function` is function specified in the `denselayer` layer, and `m` and `b` are the `.weights` and `.bias` members of the layer. Manually obtain the neuron's weight and bias, and use the pseudocode `activation_function( m*x+b )` to calculate the neuron's response to the first test example `X_test[0]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.keras.activations.sigmoid(x)>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(index=0).activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=258791, shape=(1,), dtype=float32, numpy=array([1.2346328e-07], dtype=float32)>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(index=0).activation(X_train[0] @ model.get_weights()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, find the output of a logistic regression model using `m` as the `beta` and `X_test[0]` as `x_i`. How to they compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return 1 / (1 + 1 / np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma(X_train[0] @ model.get_weights()[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "they're the same?!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The current model can't do multiclass prediction - it can only predict a single thing. Let's use it to predict if an image is a '1'. Create a binary label set `yone_train` and `yone_test` for images that are ones, and then train it like this:\n",
    "\n",
    "```\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"sgd\", metrics=[Precision(), Recall()] ) \n",
    "\n",
    "model.fit(X_train, yone_train, epochs=10, batch_size=5000, verbose=1,\n",
    "              validation_split=0.1)\n",
    "```\n",
    "\n",
    "Take a look at the `weight` and `bias` parameters of the `denselayer`. Have they changed? Now that you've considered the relationship of this neuron to logistic regression, how would you relate training this model to training a logistic regression model? (Consider taking the neuron's `weight` vector, reshaping it into a square, and rendering an image of it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 1s 26us/sample - loss: 0.4115 - precision_2: 0.9465 - recall_2: 0.9524 - val_loss: 0.3400 - val_precision_2: 0.9484 - val_recall_2: 0.9635\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 0s 7us/sample - loss: 0.3887 - precision_2: 0.9459 - recall_2: 0.9547 - val_loss: 0.3216 - val_precision_2: 0.9541 - val_recall_2: 0.9571\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 0s 9us/sample - loss: 0.3658 - precision_2: 0.9470 - recall_2: 0.9532 - val_loss: 0.3028 - val_precision_2: 0.9497 - val_recall_2: 0.9587\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 0s 8us/sample - loss: 0.3465 - precision_2: 0.9461 - recall_2: 0.9542 - val_loss: 0.2903 - val_precision_2: 0.9540 - val_recall_2: 0.9556\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.3317 - precision_2: 0.9471 - recall_2: 0.9521 - val_loss: 0.2746 - val_precision_2: 0.9482 - val_recall_2: 0.9587\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 1s 14us/sample - loss: 0.3137 - precision_2: 0.9482 - recall_2: 0.9545 - val_loss: 0.2651 - val_precision_2: 0.9525 - val_recall_2: 0.9540\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 1s 11us/sample - loss: 0.3035 - precision_2: 0.9481 - recall_2: 0.9540 - val_loss: 0.2555 - val_precision_2: 0.9554 - val_recall_2: 0.9524\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 1s 17us/sample - loss: 0.2854 - precision_2: 0.9473 - recall_2: 0.9537 - val_loss: 0.2541 - val_precision_2: 0.9562 - val_recall_2: 0.9349\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 1s 17us/sample - loss: 0.2816 - precision_2: 0.9469 - recall_2: 0.9512 - val_loss: 0.2364 - val_precision_2: 0.9555 - val_recall_2: 0.9540\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 1s 14us/sample - loss: 0.2635 - precision_2: 0.9477 - recall_2: 0.9539 - val_loss: 0.2280 - val_precision_2: 0.9551 - val_recall_2: 0.9460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3b184e5198>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yone_train = y_train==1\n",
    "yone_test = y_test==1\n",
    "\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"sgd\", metrics=[Precision(), Recall()] ) \n",
    "\n",
    "model.fit(X_train, yone_train, epochs=10, batch_size=5000, verbose=1,\n",
    "              validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression in parallel\n",
    "\n",
    "Keras allows us to perform logistic regression _in parallel_ for a large number of target classes:\n",
    "\n",
    "```python\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples, n_feats = X_train.shape\n",
    "\n",
    "model = Sequential() # sequence of layers\n",
    "\n",
    "denselayer = Dense(units=10,\n",
    "                input_dim=n_feats,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='sigmoid')\n",
    "\n",
    "model.add(denselayer)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=\"sgd\", metrics=[\"accuracy\"] )\n",
    "```\n",
    "\n",
    "1. Compile and train this model. What test accuracy does it converge to? Is it good or bad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 2s 35us/sample - loss: 4.3623 - accuracy: 0.1815 - val_loss: 3.5668 - val_accuracy: 0.1812\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 1s 23us/sample - loss: 2.7195 - accuracy: 0.1843 - val_loss: 2.2735 - val_accuracy: 0.1838\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 1s 25us/sample - loss: 2.2984 - accuracy: 0.1871 - val_loss: 2.2410 - val_accuracy: 0.1863\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 1s 24us/sample - loss: 2.2743 - accuracy: 0.1908 - val_loss: 2.2223 - val_accuracy: 0.1892\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 1s 22us/sample - loss: 2.2582 - accuracy: 0.1962 - val_loss: 2.2106 - val_accuracy: 0.1967\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 1s 26us/sample - loss: 2.2443 - accuracy: 0.2017 - val_loss: 2.1993 - val_accuracy: 0.2015\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 3s 54us/sample - loss: 2.2310 - accuracy: 0.2086 - val_loss: 2.1877 - val_accuracy: 0.2078\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 2.2179 - accuracy: 0.2147 - val_loss: 2.1760 - val_accuracy: 0.2117\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 2s 28us/sample - loss: 2.2050 - accuracy: 0.2191 - val_loss: 2.1635 - val_accuracy: 0.2168\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 2s 33us/sample - loss: 2.1911 - accuracy: 0.2244 - val_loss: 2.1522 - val_accuracy: 0.2223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3ac1f3e908>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_samples, n_feats = X_train.shape\n",
    "\n",
    "model = Sequential() # sequence of layers\n",
    "\n",
    "denselayer = Dense(units=10,\n",
    "                input_dim=n_feats,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='sigmoid')\n",
    "\n",
    "model.add(denselayer)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=\"sgd\", metrics=[\"accuracy\"] )\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "model.fit(X_train, to_categorical(y_train), epochs=10, batch_size=5000, verbose=1,\n",
    "              validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.987779  , 1.        , 0.9999999 , 1.        , 0.02766117,\n",
       "       1.        , 0.        , 1.        , 0.7899191 , 1.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the model to find a probabilistic prediction on any item in `X_test`. What is the _sum of probabilities_ for every predicted class?\n",
    "\n",
    "You'll notice the predictions are hot garbage (with an accuracy around 20%), and that the class probabilities for every class sum to more than 1.0.\n",
    "\n",
    "One solution is to apply a function to the neuron outputs that normalizes the vector such that it's constrained to add up to 1.0, and then on a loss from _that_ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7545.1807, 5831.2075, 9792.941 , 9143.842 , 8151.522 , 9894.979 ,\n",
       "       9627.504 , 9207.542 , 9920.99  , 8872.526 ], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 1.0000000e+00,\n",
       "        1.0000000e+00, 9.9999970e-01],\n",
       "       [9.9732888e-01, 1.0000000e+00, 1.0000000e+00, ..., 6.1809540e-01,\n",
       "        1.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ..., 8.6814165e-05,\n",
       "        2.3722827e-02, 1.0000000e+00],\n",
       "       ...,\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 1.0000000e+00,\n",
       "        1.0000000e+00, 1.0000000e+00],\n",
       "       [0.0000000e+00, 1.0000000e+00, 1.0000000e+00, ..., 1.0000000e+00,\n",
       "        1.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 4.7272712e-02, 1.0000000e+00, ..., 9.9999988e-01,\n",
       "        1.0000000e+00, 1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Change the `activation` argument to \"softmax\", and retrain the model. What is the test accuracy? What is the sum of classification probabilities for all classes, for a single prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 1s 20us/sample - loss: 153.7726 - accuracy: 0.4230 - val_loss: 44.7059 - val_accuracy: 0.7160\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 1s 14us/sample - loss: 27.2652 - accuracy: 0.7653 - val_loss: 59.4212 - val_accuracy: 0.7413\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 1s 14us/sample - loss: 21.8269 - accuracy: 0.8121 - val_loss: 27.9500 - val_accuracy: 0.8032\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 1s 14us/sample - loss: 22.1566 - accuracy: 0.7858 - val_loss: 11.4100 - val_accuracy: 0.8588\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 1s 14us/sample - loss: 10.2670 - accuracy: 0.8648 - val_loss: 6.4511 - val_accuracy: 0.9008\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 9.0593 - accuracy: 0.8696 - val_loss: 16.9906 - val_accuracy: 0.7938\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 1s 19us/sample - loss: 18.2243 - accuracy: 0.8241 - val_loss: 6.4388 - val_accuracy: 0.8977\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 1s 22us/sample - loss: 22.5004 - accuracy: 0.7911 - val_loss: 18.8705 - val_accuracy: 0.8357\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 1s 21us/sample - loss: 9.1741 - accuracy: 0.8800 - val_loss: 5.5922 - val_accuracy: 0.9118\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 12.9840 - accuracy: 0.8515 - val_loss: 24.3765 - val_accuracy: 0.7357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3ae38ed8d0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_samples, n_feats = X_train.shape\n",
    "\n",
    "model = Sequential() # sequence of layers\n",
    "\n",
    "denselayer = Dense(units=10,\n",
    "                input_dim=n_feats,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='softmax')\n",
    "\n",
    "model.add(denselayer)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"sgd\", metrics=[\"accuracy\"] )\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "model.fit(X_train, to_categorical(y_train), epochs=10, batch_size=5000, verbose=1,\n",
    "              validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra credit: train with a large `batch` argument in `.fit`, and make pictures of the unit weights reshaped into 28x28 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptrons: logistic regression with hidden features\n",
    "\n",
    "A perceptron is an architecture whereby an input is classified into a number of features; features that are actually unknown when model training begins. Then, logistic regression (or softmax regression) using the _hidden features_ as inputs is used to find the final class probabilities. This architecture is called a \"perceptron\", \"multiplayer perceptron\", or \"MLP\". Here's how to define an MLP with 300 neurons in one hidden layer, using Keras:\n",
    "\n",
    "```python\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples, n_feats = X_train.shape\n",
    "\n",
    "model = Sequential() # sequence of layers\n",
    "\n",
    "hidden_units = 300\n",
    "n_classes = 10\n",
    "\n",
    "hidden_layer = Dense(units=hidden_units,\n",
    "                input_dim=n_feats,\n",
    "                kernel_initializer='constant',\n",
    "                activation='sigmoid')\n",
    "\n",
    "output_layer = Dense(units=n_classes,\n",
    "                input_dim=hidden_units,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='softmax')\n",
    "\n",
    "model.add(hidden_layer)\n",
    "model.add(output_layer)\n",
    "```\n",
    "\n",
    "1. Compile and train this model on the MNIST dataset. The 'adam' optimizer tends to do well. What kind of accuracy do you get? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 39s 648us/sample - loss: 0.4423 - accuracy: 0.8844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3ada989c50>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_samples, n_feats = X_train.shape\n",
    "\n",
    "model = Sequential() # sequence of layers\n",
    "\n",
    "hidden_units = 300\n",
    "n_classes = 10\n",
    "\n",
    "hidden_layer = Dense(units=hidden_units,\n",
    "                input_dim=n_feats,\n",
    "                kernel_initializer='constant',\n",
    "                activation='sigmoid')\n",
    "\n",
    "output_layer = Dense(units=n_classes,\n",
    "                input_dim=hidden_units,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='softmax')\n",
    "\n",
    "model.add(hidden_layer)\n",
    "model.add(output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, to_categorical(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Vary the hyperparameters. Choose differnet activations, kernal initializers, hidden units, optimizers, and optimizer parameters. To access optimizer parameters, instantiate optimizer objects from `tensorflow.keras.optimizers`. Can you get a better accuracy than 94%?\n",
    "\n",
    "This task might feel a little like looking for a needle in a haystack.  Perhaps you can think of an automated approach instead of a manual brute force search? (but with some intuition the brute force search will get you there, too.)  Keras has a [wrapper](https://keras.io/scikit-learn-api/) for the scikit-learn API where you can interface with GridSearch.  See this [blog post.](https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 24s 394us/sample - loss: 0.4247 - accuracy: 0.8879\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 21s 344us/sample - loss: 0.3122 - accuracy: 0.9115\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 19s 316us/sample - loss: 0.2891 - accuracy: 0.9160\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 19s 317us/sample - loss: 0.2652 - accuracy: 0.9207\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 24s 398us/sample - loss: 0.2494 - accuracy: 0.9236\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 47s 785us/sample - loss: 0.2457 - accuracy: 0.9252\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 54s 902us/sample - loss: 0.2348 - accuracy: 0.9287\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 30s 495us/sample - loss: 0.2307 - accuracy: 0.9304\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 34s 574us/sample - loss: 0.2242 - accuracy: 0.9323\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 35s 588us/sample - loss: 0.2188 - accuracy: 0.9334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3ac6cb5160>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_samples, n_feats = X_train.shape\n",
    "\n",
    "model = Sequential() # sequence of layers\n",
    "\n",
    "hidden_units = 300\n",
    "n_classes = 10\n",
    "\n",
    "hidden_layer = Dense(units=hidden_units,\n",
    "                input_dim=n_feats,\n",
    "                kernel_initializer='constant',\n",
    "                activation='sigmoid')\n",
    "\n",
    "output_layer = Dense(units=n_classes,\n",
    "                input_dim=hidden_units,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='softmax')\n",
    "\n",
    "model.add(hidden_layer)\n",
    "# model.add(Dense(units=hidden_units,\n",
    "#                 input_dim=hidden_units,\n",
    "#                 kernel_initializer='uniform',\n",
    "#                 activation='softmax'))\n",
    "model.add(output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, to_categorical(y_train), epochs=10, batch=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. When you have a very good accuracy, make a picture of the weights associated with the hidden layers.\n",
    "\n",
    "Hint: do this, \n",
    "```python\n",
    "hidden_unit_i = 0\n",
    "plt.imshow(hidden_layer.weights[0].numpy()[:,hidden_unit_i].reshape(28,28))\n",
    "```\n",
    "\n",
    "Speculate on what this might mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3ac30b1e80>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_unit_i = 0\n",
    "plt.imshow(hidden_layer.weights[0].numpy()[:,hidden_unit_i].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation for PCs with NVIDIA GPUs that wish to use the GPU to speed up training.  \n",
    "\n",
    "1) Go [here](https://github.com/NVIDIA/nvidia-docker) and follow the directions to install `nvidia-docker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Check that it works:  \n",
    "   ```bash\n",
    "   $ docker run --gpus all nvidia/cuda:9.0-base nvidia-smi\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Download an image, make a container and a volume:\n",
    "   ```\n",
    "   $ cd ~\n",
    "   $ docker run --gpus all -it --name tensorflow-gpu -p 8888:8888 -v \"$PWD\":/tf tensorflow/tensorflow:latest-gpu-py3-jupyter\n",
    "   ```\n",
    "\n",
    "As discussed in Part I, you can work with the container in a Jupyter notebook or from terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
