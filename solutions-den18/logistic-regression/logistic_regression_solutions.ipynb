{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from statsmodels.tools import add_constant\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from roc_curve import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: ROC Curve\n",
    "\n",
    "1. Write an ROC curve function to compute the above in `roc_curve.py`.\n",
    "\n",
    "    See [roc_curve.py](roc_curve.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Run the above code to verify that it's working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_fake_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Let's see how the roc curve looks on a real dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_loan_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Exploration: Graduate School Admissions\n",
    "\n",
    "1. Load in the dataset into pandas: `data/grad.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/grad.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the pandas `describe` method to get some preliminary summary statistics on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Make a bar plot of the percent of applicants from each rank who were accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admit = pd.crosstab(df['admit'], df['rank'], rownames=['admit'])\n",
    "(admit / admit.apply(sum)).plot(kind=\"bar\", figsize=(12, 6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What does the distribution of the GPA and GRE scores look like? Do the distributions differ much?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(12, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   *The distributions of GPA and GRE actually look quite similar, possibly normally distributed slightly skewed to the left (negative skew) centered around the means of GPA and GRE computed above. And for GPAs there is an anomolous bump near 4.0s.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. One of the issues with classification can be unbalanced classes. What percentage of the data was admitted? Do you think this will be a problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['admit'].value_counts() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   *Classes aren't too imbalanced so you should be fine.\n",
    "    When dealing with data where the label could potentially be something that is biased one way or the other (such as acceptance, fraud, signups, anything where one label is more preferential to the other or deals with some measure of \"success\") you should verify. Actually you should most always verify.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Predicting Graduate School Admissions\n",
    "\n",
    "1. Use statsmodels to fit a Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['gre', 'gpa', 'rank']].values\n",
    "X_const = add_constant(X, prepend=True)\n",
    "y = df['admit'].values\n",
    "\n",
    "logit_model = Logit(y, X_const).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the `summary` method to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the p-values are all smaller than 0.05, so we are very happy with this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use sklearn's [KFold cross validation](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html) to calculate the average accuracy, precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10)\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "for train_index, test_index in kfold.split(X_train):\n",
    "    model = LogisticRegression(solver=\"lbfgs\")\n",
    "    model.fit(X_train.iloc[train_index], y_train.iloc[train_index])\n",
    "    y_predict = model.predict(X_train.iloc[test_index])\n",
    "    y_true = y_train.iloc[test_index]\n",
    "    accuracies.append(accuracy_score(y_true, y_predict))\n",
    "    precisions.append(precision_score(y_true, y_predict))\n",
    "    recalls.append(recall_score(y_true, y_predict))\n",
    "\n",
    "print(\"Accuracy:\", np.average(accuracies))\n",
    "print(\"Precision:\", np.average(precisions))\n",
    "print(\"Recall:\", np.average(recalls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. The `rank` column is numerical, but as it has 4 buckets, we could also consider it to be categorical. Use panda's [get_dummies](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.reshape.get_dummies.html) to binarize the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df['rank'], prefix='rank')\n",
    "X2 = df[['gre','gpa']].join(dummies.loc[:,'rank_2':]).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Compute the same metrics as above. Does it do better or worse with the rank column binarized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "X2_train, X2_test, y_train, y_test = train_test_split(X2, y)\n",
    "\n",
    "for train_index, test_index in kfold.split(X2_train):\n",
    "    model = LogisticRegression(solver=\"lbfgs\", max_iter=500)\n",
    "    model.fit(X2_train.iloc[train_index], y_train.iloc[train_index])\n",
    "    y_predict = model.predict(X2_train.iloc[test_index])\n",
    "    y_true = y_train.iloc[test_index]\n",
    "    accuracies.append(accuracy_score(y_true, y_predict))\n",
    "    precisions.append(precision_score(y_true, y_predict))\n",
    "    recalls.append(recall_score(y_true, y_predict))\n",
    "\n",
    "print(\"Accuracy:\", np.average(accuracies))\n",
    "print(\"Precision:\", np.average(precisions))\n",
    "print(\"Recall:\", np.average(recalls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    *It seems to perform worse.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Make a plot of the ROC curve (using your function defined in Part 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting helper function\n",
    "def simple_plot(ax, x, y, x_label, y_label, title):\n",
    "    ax.plot(x, y)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "probabilities = model.predict_proba(X_test)[:, 1]\n",
    "tpr, fpr, thresholds = roc_curve(probabilities, y_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "simple_plot(ax, fpr, tpr, \n",
    "            \"False Positive Rate (1 - Specificity)\", \n",
    "            \"True Positive Rate (Sensitivity, Recall)\", \n",
    "            \"ROC Plot of Admissions Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Is it possible to pick a threshold where TPR > 60% and FPR < 40%? What is the threshold?\n",
    "\n",
    "    *Yes. We can get a TPR of 62.5% and FPR of 33.8% with a threshold of 0.3617.*\n",
    "\n",
    "    *Answers may vary!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Say we are using this as a first step in the application process. We want to weed out clearly unqualified candidates, but not reject too many candidates. What might be a good choice of threshold?\n",
    "\n",
    "    *We want to maximize the TPR and don't care as much about the FPR. With a threshold of 0.222, we can get a TPR of 96.9%. THe FPR will be 73.5%, but we are okay with this sacrifice in order to avoid false negatives.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Interpreting the beta coefficients with the Odds Ratio\n",
    "\n",
    "1. Fit a Logistic Regression model on all the data. What are the beta coefficients? You should have 3 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X, y)\n",
    "\n",
    "for name, coef in zip(df.columns[1:], model.coef_[0]):\n",
    "    print(\"{0}: {1:0.4f}\".format(name, coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Compute the change in odds ratio from a one unit change in each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, coef in enumerate(model.coef_[0]):\n",
    "    print(\"beta{0}: {1:0.5f}\".format(i + 1, np.exp(coef)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a sentence for each of the three features.\n",
    "\n",
    "    *Increasing the GRE score by 1 point increases the chance of getting in by a factor of 1.00189.*\n",
    "\n",
    "    *Increasing the GPA score by 1 point increases the chance of getting in by a factor of 1.37614.*\n",
    "\n",
    "    *Improving the school's rank by 1 point (means decreasing the number) increases the chance of getting in by a factor of 1/0.54587=1.8319.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What change is required to double my chances of admission?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, coef in enumerate(model.coef_[0]):\n",
    "    print(\"beta{0}: {1:0.5f}\".format(i + 1, np.log(2) / coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   *Increasing the GRE score by 367 points doubles the chance of getting in.*\n",
    "\n",
    "   *Increasing the GPA score by 2.17 points doubles the chance of getting in.*\n",
    "\n",
    "   *Decreasing (improving) the school rank by 1.14 doubles the chance of getting in.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Predicted Probabilities\n",
    "\n",
    "Now let's actually play with our data to verify what we calculated above with the Odds Ratio.\n",
    "\n",
    "1. Create a new feature matrix which has four rows. It should have each of the four possible values for the rank and keep the GRE and GPA values fixed. Use the mean value as a reasonable value to fix them at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gre = df['gre'].mean()\n",
    "gpa = df['gpa'].mean()\n",
    "feature_matrix = []\n",
    "ranks = [1, 2, 3, 4]\n",
    "for rank in ranks:\n",
    "    feature_matrix.append([gre, gpa, rank])\n",
    "X_rank = np.array(feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fit the Logistic Regression model on all the data and then use the model's `predict_proba` method to compute the predicted probabilities of this fake feature matrix. Also include the odds (`p/(1-p)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_rank = model.predict_proba(X_rank)[:, 1]\n",
    "for rank, prob in zip(ranks, probabilities_rank):\n",
    "    print(\"rank: {0}, probability: {1:0.5f}, odds: {2:0.5f}\".format(rank, prob, prob / (1 - prob)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Make a plot of the rank vs the probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "simple_plot(ax, ranks, probabilities_rank, \n",
    "            \"Rank\", \n",
    "            \"Probability\",\n",
    "            \"Affect of Modifying the Rank on Probability of Acceptance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another function to make things look nicer\n",
    "def double_odds_plot(x, y, x_label):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    title = \"Affect of Modifying the {0} on Odds of Acceptance\".format(x_label)\n",
    "    log_title = \"Affect of Modifying the {0} on Log Odds of Acceptance\".format(x_label)\n",
    "    \n",
    "    simple_plot(axes[0], x, y, x_label, \"Odds\", title)\n",
    "    \n",
    "    simple_plot(axes[1], x, np.log(y), x_label, \"Log Odds\", log_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Make a plot of the rank vs the odds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Since we really care about how a linear change in rank changes the probability by a multiplicative factor, we should do a graph of the rank vs the log of the odds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_rank = probabilities_rank / (1 - probabilities_rank)\n",
    "\n",
    "double_odds_plot(ranks, odds_rank, \"Rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Note that the slope of this line is approximately `(0 + 1.7) / (4 - 1) = -0.567`, which is approximately the beta coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Do the same analysis (#1-5) with the GRE and GPA scores. Each time, create a feature matrix with the other two columns fixed at the mean and every possible value of the column in question.\n",
    "\n",
    "    ***Measuring the affect of modifying the GRE score on the probability of acceptance***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpa = df['gpa'].mean()\n",
    "rank = df['rank'].mean()\n",
    "feature_matrix = []\n",
    "gres = range(df['gre'].min(), df['gre'].max() + 1)\n",
    "for gre in gres:\n",
    "    feature_matrix.append([gre, gpa, rank])\n",
    "X_gre = np.array(feature_matrix)\n",
    "\n",
    "probabilities_gre = model.predict_proba(X_gre)[:, 1]\n",
    "for gre, prob in zip(gres, probabilities_gre):\n",
    "    print(\"gre: {0}, probability: {1:0.5f}, odds: {2:0.5f}\".format(gre, prob, prob / (1 - prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "simple_plot(ax, gres, probabilities_gre,\n",
    "            \"GRE\",\n",
    "            \"Probability\",\n",
    "            \"Affect of Modifying the GRE on Probability of Acceptance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_gre = probabilities_gre / (1 - probabilities_gre)\n",
    "\n",
    "double_odds_plot(gres, odds_gre, \"GRE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Note that the slope of this line is approximately `(-.4 + 1.55) / (800 - 220) = -0.00198`, which is approximately the beta coefficient.\n",
    "\n",
    "    ***Measuring the affect of modifying the GPA score on the probability of acceptance***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gre = df['gre'].mean()\n",
    "rank = df['rank'].mean()\n",
    "feature_matrix = []\n",
    "gpas = range(int(np.floor(df['gpa'].min())), int(np.ceil(df['gpa'].max() + 1)))\n",
    "for gpa in gpas:\n",
    "    feature_matrix.append([gre, gpa, rank])\n",
    "X_gpa = np.array(feature_matrix)\n",
    "\n",
    "probabilities_gpa = model.predict_proba(X_gpa)[:, 1]\n",
    "for gpa, prob in zip(gpas, probabilities_gpa):\n",
    "    print(\"gpa: {0}, probability: {1:0.5f}, odds: {2:0.5f}\".format(gpa, prob, prob / (1 - prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "simple_plot(ax, gpas, probabilities_gpa,\n",
    "            \"GPA\",\n",
    "            \"Probability\",\n",
    "            \"Affect of Modifying the GPA on Probability of Acceptance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_gpa = probabilities_gpa / (1 - probabilities_gpa)\n",
    "\n",
    "double_odds_plot(gpas, odds_gpa, \"GPA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
