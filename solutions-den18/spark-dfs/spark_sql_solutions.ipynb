{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Initiating a `SparkSession`\n",
    "\n",
    "1\\. Initiate a `SparkSession`. A `SparkSession` initializes both a `SparkContext` and a `SQLContext` to use RDD-based and DataFrame-based functionalities of Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as ps    # for the pyspark suite\n",
    "\n",
    "spark = ps.sql.SparkSession.builder \\\n",
    "            .master(\"local[4]\") \\\n",
    "            .appName(\"df lecture\") \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Introduction to SparkSQL\n",
    "\n",
    "SparkSQL allows you to execute relational queries on **structured** data using \n",
    "Spark. Today we'll get some practice with this by running some queries on a \n",
    "Yelp dataset. To begin, you will load data into a Spark `DataFrame`, which can \n",
    "then be queried as a SQL table. \n",
    "\n",
    "1\\. Load the Yelp business data using the function `.read.json()` from the `SparkSession()` object, with input file `data/yelp_academic_dataset_business.json.gz`.\n",
    "\n",
    "2\\. Print the schema and register the `yelp_business_df` as a temporary \n",
    "table named `yelp_business` (this will enable us to query the table later using \n",
    "our `SparkSession()` object).\n",
    "\n",
    "Now, you can run SQL queries on the `yelp_business` table. For example:\n",
    "\n",
    "```python\n",
    "result = spark.sql(\"SELECT name, city, state, stars FROM yelp_business LIMIT 10\")\n",
    "result.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- attributes: struct (nullable = true)\n",
      " |    |-- Accepts Credit Cards: string (nullable = true)\n",
      " |    |-- Accepts Insurance: boolean (nullable = true)\n",
      " |    |-- Ages Allowed: string (nullable = true)\n",
      " |    |-- Alcohol: string (nullable = true)\n",
      " |    |-- Ambience: struct (nullable = true)\n",
      " |    |    |-- casual: boolean (nullable = true)\n",
      " |    |    |-- classy: boolean (nullable = true)\n",
      " |    |    |-- divey: boolean (nullable = true)\n",
      " |    |    |-- hipster: boolean (nullable = true)\n",
      " |    |    |-- intimate: boolean (nullable = true)\n",
      " |    |    |-- romantic: boolean (nullable = true)\n",
      " |    |    |-- touristy: boolean (nullable = true)\n",
      " |    |    |-- trendy: boolean (nullable = true)\n",
      " |    |    |-- upscale: boolean (nullable = true)\n",
      " |    |-- Attire: string (nullable = true)\n",
      " |    |-- BYOB: boolean (nullable = true)\n",
      " |    |-- BYOB/Corkage: string (nullable = true)\n",
      " |    |-- By Appointment Only: boolean (nullable = true)\n",
      " |    |-- Caters: boolean (nullable = true)\n",
      " |    |-- Coat Check: boolean (nullable = true)\n",
      " |    |-- Corkage: boolean (nullable = true)\n",
      " |    |-- Delivery: boolean (nullable = true)\n",
      " |    |-- Dietary Restrictions: struct (nullable = true)\n",
      " |    |    |-- dairy-free: boolean (nullable = true)\n",
      " |    |    |-- gluten-free: boolean (nullable = true)\n",
      " |    |    |-- halal: boolean (nullable = true)\n",
      " |    |    |-- kosher: boolean (nullable = true)\n",
      " |    |    |-- soy-free: boolean (nullable = true)\n",
      " |    |    |-- vegan: boolean (nullable = true)\n",
      " |    |    |-- vegetarian: boolean (nullable = true)\n",
      " |    |-- Dogs Allowed: boolean (nullable = true)\n",
      " |    |-- Drive-Thru: boolean (nullable = true)\n",
      " |    |-- Good For: struct (nullable = true)\n",
      " |    |    |-- breakfast: boolean (nullable = true)\n",
      " |    |    |-- brunch: boolean (nullable = true)\n",
      " |    |    |-- dessert: boolean (nullable = true)\n",
      " |    |    |-- dinner: boolean (nullable = true)\n",
      " |    |    |-- latenight: boolean (nullable = true)\n",
      " |    |    |-- lunch: boolean (nullable = true)\n",
      " |    |-- Good For Dancing: boolean (nullable = true)\n",
      " |    |-- Good For Groups: boolean (nullable = true)\n",
      " |    |-- Good For Kids: boolean (nullable = true)\n",
      " |    |-- Good for Kids: boolean (nullable = true)\n",
      " |    |-- Hair Types Specialized In: struct (nullable = true)\n",
      " |    |    |-- africanamerican: boolean (nullable = true)\n",
      " |    |    |-- asian: boolean (nullable = true)\n",
      " |    |    |-- coloring: boolean (nullable = true)\n",
      " |    |    |-- curly: boolean (nullable = true)\n",
      " |    |    |-- extensions: boolean (nullable = true)\n",
      " |    |    |-- kids: boolean (nullable = true)\n",
      " |    |    |-- perms: boolean (nullable = true)\n",
      " |    |    |-- straightperms: boolean (nullable = true)\n",
      " |    |-- Happy Hour: boolean (nullable = true)\n",
      " |    |-- Has TV: boolean (nullable = true)\n",
      " |    |-- Music: struct (nullable = true)\n",
      " |    |    |-- background_music: boolean (nullable = true)\n",
      " |    |    |-- dj: boolean (nullable = true)\n",
      " |    |    |-- jukebox: boolean (nullable = true)\n",
      " |    |    |-- karaoke: boolean (nullable = true)\n",
      " |    |    |-- live: boolean (nullable = true)\n",
      " |    |    |-- playlist: boolean (nullable = true)\n",
      " |    |    |-- video: boolean (nullable = true)\n",
      " |    |-- Noise Level: string (nullable = true)\n",
      " |    |-- Open 24 Hours: boolean (nullable = true)\n",
      " |    |-- Order at Counter: boolean (nullable = true)\n",
      " |    |-- Outdoor Seating: boolean (nullable = true)\n",
      " |    |-- Parking: struct (nullable = true)\n",
      " |    |    |-- garage: boolean (nullable = true)\n",
      " |    |    |-- lot: boolean (nullable = true)\n",
      " |    |    |-- street: boolean (nullable = true)\n",
      " |    |    |-- valet: boolean (nullable = true)\n",
      " |    |    |-- validated: boolean (nullable = true)\n",
      " |    |-- Payment Types: struct (nullable = true)\n",
      " |    |    |-- amex: boolean (nullable = true)\n",
      " |    |    |-- cash_only: boolean (nullable = true)\n",
      " |    |    |-- discover: boolean (nullable = true)\n",
      " |    |    |-- mastercard: boolean (nullable = true)\n",
      " |    |    |-- visa: boolean (nullable = true)\n",
      " |    |-- Price Range: long (nullable = true)\n",
      " |    |-- Smoking: string (nullable = true)\n",
      " |    |-- Take-out: boolean (nullable = true)\n",
      " |    |-- Takes Reservations: boolean (nullable = true)\n",
      " |    |-- Waiter Service: boolean (nullable = true)\n",
      " |    |-- Wheelchair Accessible: boolean (nullable = true)\n",
      " |    |-- Wi-Fi: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- categories: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- full_address: string (nullable = true)\n",
      " |-- hours: struct (nullable = true)\n",
      " |    |-- Friday: struct (nullable = true)\n",
      " |    |    |-- close: string (nullable = true)\n",
      " |    |    |-- open: string (nullable = true)\n",
      " |    |-- Monday: struct (nullable = true)\n",
      " |    |    |-- close: string (nullable = true)\n",
      " |    |    |-- open: string (nullable = true)\n",
      " |    |-- Saturday: struct (nullable = true)\n",
      " |    |    |-- close: string (nullable = true)\n",
      " |    |    |-- open: string (nullable = true)\n",
      " |    |-- Sunday: struct (nullable = true)\n",
      " |    |    |-- close: string (nullable = true)\n",
      " |    |    |-- open: string (nullable = true)\n",
      " |    |-- Thursday: struct (nullable = true)\n",
      " |    |    |-- close: string (nullable = true)\n",
      " |    |    |-- open: string (nullable = true)\n",
      " |    |-- Tuesday: struct (nullable = true)\n",
      " |    |    |-- close: string (nullable = true)\n",
      " |    |    |-- open: string (nullable = true)\n",
      " |    |-- Wednesday: struct (nullable = true)\n",
      " |    |    |-- close: string (nullable = true)\n",
      " |    |    |-- open: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- neighborhoods: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- open: boolean (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n",
      "61184\n"
     ]
    }
   ],
   "source": [
    "yelp_business_df = spark.read.json('data/yelp_academic_dataset_business.json.gz')\n",
    "\n",
    "yelp_business_df.printSchema()\n",
    "\n",
    "print(yelp_business_df.count())\n",
    "\n",
    "yelp_business_df.createOrReplaceTempView(\"yelp_business\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-----+-----+\n",
      "|                name|       city|state|stars|\n",
      "+--------------------+-----------+-----+-----+\n",
      "|   Eric Goldberg, MD|    Phoenix|   AZ|  3.5|\n",
      "|        Clancy's Pub| Dravosburg|   PA|  3.5|\n",
      "|Cool Springs Golf...|Bethel Park|   PA|  2.5|\n",
      "|    Verizon Wireless| Pittsburgh|   PA|  3.5|\n",
      "|       Emil's Lounge|   Braddock|   PA|  4.5|\n",
      "|Alexion's Bar & G...|   Carnegie|   PA|  4.0|\n",
      "|Flynn's E W Tire ...|   Carnegie|   PA|  1.5|\n",
      "|Forsythe Miniatur...|   Carnegie|   PA|  4.0|\n",
      "|Quaker State Cons...|   Carnegie|   PA|  2.5|\n",
      "|Kings Family Rest...|   Carnegie|   PA|  3.5|\n",
      "+--------------------+-----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"SELECT name, city, state, stars FROM yelp_business LIMIT 10\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Write a query or a sequence of transformations that returns the `name` of entries that fulfill the following \n",
    "conditions:\n",
    "\n",
    "   - Rated at 5 `stars`\n",
    "   - In the `city` of Phoenix\n",
    "   - Accepts credit card (Reference the `'Accepts Credit Card'` field by \n",
    "   ``` attributes.`Accepts Credit Cards` ```.  **NOTE**: We are actually looking for the value `'true'`, not the boolean value True!)\n",
    "   - Contains Restaurants in the `categories` array.  \n",
    "\n",
    "   Hint: `LATERAL VIEW explode()` can be used to access the individual elements\n",
    "   of an array (i.e. the `categories` array). For reference, you can see the \n",
    "   [first example](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+LateralView) on this page.\n",
    "   \n",
    "   Hint: In spark, while using `filter()` or `where()`, you can create a condition that tests if a column, made of an array, contains a given value. The functions is [pyspark.sql.functions.array_contains](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.array_contains)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(name='Auslers Grill')\n",
      "Row(name=\"Mulligan's Restaurant\")\n",
      "Row(name='Sunfare')\n",
      "Row(name='Subway')\n",
      "Row(name=\"Lil Cal's\")\n",
      "Row(name=\"Ed's\")\n",
      "Row(name='Frenchys Caribbean Dogs')\n",
      "Row(name='WY Market')\n",
      "Row(name='Pollo Sabroso')\n",
      "Row(name='Queen Creek Olive Mill Oils & Olives Biltmore Fashion Park')\n",
      "Row(name='Gluten Free Creations Bakery')\n",
      "Row(name='Panini Bread and Grill')\n",
      "Row(name='One Eighty Q')\n",
      "Row(name='Saffron JAK Original Stonebread Pizzas')\n",
      "Row(name='Los Primos Carniceria')\n",
      "Row(name=\"Bertie's Of Arcadia\")\n",
      "Row(name='Little Miss BBQ')\n",
      "Row(name='Las Jicaras Mexican Grill')\n",
      "Row(name='Santos Lucha Libre')\n",
      "Row(name='Taqueria El Chino')\n",
      "Row(name=\"Filiberto's Mexican Food\")\n",
      "Row(name='Helpings Cafe, Market and Catering')\n",
      "Row(name='Altamimi Restutant')\n",
      "Row(name='Tacos Huicho')\n",
      "Row(name=\"Jimmy John's\")\n",
      "Row(name='Ten Handcrafted American Fare & Spirits')\n",
      "Row(name='The Brown Bag')\n",
      "Row(name='Coe Casa')\n",
      "Row(name=\"Adela's Italian\")\n",
      "Row(name='The Loaded Potato')\n",
      "Row(name='Banh Mi Bistro Vietnamese Eatery')\n",
      "Row(name='Couscous Express')\n",
      "______________________________\n",
      "+--------------------+\n",
      "|                name|\n",
      "+--------------------+\n",
      "|       Auslers Grill|\n",
      "|Mulligan's Restau...|\n",
      "|             Sunfare|\n",
      "|              Subway|\n",
      "|           Lil Cal's|\n",
      "|                Ed's|\n",
      "|Frenchys Caribbea...|\n",
      "|           WY Market|\n",
      "|       Pollo Sabroso|\n",
      "|Queen Creek Olive...|\n",
      "|Gluten Free Creat...|\n",
      "|Panini Bread and ...|\n",
      "|        One Eighty Q|\n",
      "|Saffron JAK Origi...|\n",
      "|Los Primos Carnic...|\n",
      "| Bertie's Of Arcadia|\n",
      "|     Little Miss BBQ|\n",
      "|Las Jicaras Mexic...|\n",
      "|  Santos Lucha Libre|\n",
      "|   Taqueria El Chino|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, array_contains\n",
    "\n",
    "out = yelp_business_df.filter((col('stars') == 5) &\n",
    "                        (col('city') == 'Phoenix') &\n",
    "                        (col('attributes.`Accepts Credit Cards`') == 'true') &\n",
    "                        (array_contains(col('categories'),'Restaurants'))).select('name')\n",
    "[print(row) for row in out.collect()]\n",
    "print('___'*10)\n",
    "print(out.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Panini Bread and Grill'),\n",
       " Row(name='Gluten Free Creations Bakery'),\n",
       " Row(name='Ten Handcrafted American Fare & Spirits'),\n",
       " Row(name='One Eighty Q'),\n",
       " Row(name='Subway'),\n",
       " Row(name='Banh Mi Bistro Vietnamese Eatery'),\n",
       " Row(name='Tacos Huicho'),\n",
       " Row(name='Helpings Cafe, Market and Catering'),\n",
       " Row(name='Sunfare'),\n",
       " Row(name=\"Bertie's Of Arcadia\"),\n",
       " Row(name='Los Primos Carniceria'),\n",
       " Row(name='The Brown Bag'),\n",
       " Row(name='Little Miss BBQ'),\n",
       " Row(name='Auslers Grill'),\n",
       " Row(name=\"Adela's Italian\"),\n",
       " Row(name='Coe Casa'),\n",
       " Row(name='Altamimi Restutant'),\n",
       " Row(name='Las Jicaras Mexican Grill'),\n",
       " Row(name='Queen Creek Olive Mill Oils & Olives Biltmore Fashion Park'),\n",
       " Row(name='Saffron JAK Original Stonebread Pizzas'),\n",
       " Row(name='Couscous Express'),\n",
       " Row(name='The Loaded Potato'),\n",
       " Row(name='Santos Lucha Libre'),\n",
       " Row(name=\"Mulligan's Restaurant\"),\n",
       " Row(name='Taqueria El Chino'),\n",
       " Row(name=\"Jimmy John's\"),\n",
       " Row(name=\"Lil Cal's\"),\n",
       " Row(name='Frenchys Caribbean Dogs'),\n",
       " Row(name=\"Ed's\"),\n",
       " Row(name=\"Filiberto's Mexican Food\"),\n",
       " Row(name='Pollo Sabroso'),\n",
       " Row(name='WY Market')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT DISTINCT name from yelp_business\n",
    "                   LATERAL VIEW explode(categories) c AS category\n",
    "                   WHERE stars = 5 \n",
    "                   AND city = 'Phoenix'\n",
    "                   AND attributes.`Accepts Credit Cards` = 'true'\n",
    "                   AND category = 'Restaurants'\"\"\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Spark and SparkSQL in Practice \n",
    "\n",
    "Now that we have a basic knowledge of how SparkSQL works, let's try dealing with a real-life scenario where some data manipulation/cleaning is required before we can query the data with SparkSQL. We will be using a dataset of user information and a data set of purchases that our users have made. We'll be cleaning the data in a regular Spark RDD before querying it with SparkSQL.\n",
    "\n",
    "   1\\. Load a dataframe `users` from `data/users.txt` using `spark.read.csv` with the following parameters: no headers, use separator `\";\"`, and infer the schema of the underlying data (for now). Use `.show(5)` and `.printSchema()` to check the result.\n",
    "   \n",
    "   2\\. Create a schema for this dataset using proper names and types for the columns, using types from the `pyspark.sql.types` module (see lecture). Use that schema to read the `users` dataframe again and use `.printSchema()` to check the result.\n",
    "   \n",
    "   Note: Each row in the `users` file represents the user with his/her `user_id, name, email, phone`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the many data types\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# create a schema of your own\n",
    "users_schema = StructType( [\n",
    "    StructField('user_id',IntegerType(),True),\n",
    "    StructField('name',StringType(),True),\n",
    "    StructField('email',StringType(),True),\n",
    "    StructField('phone',StringType(),True) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+--------------------+--------------------+\n",
      "|   user_id|             name|               email|               phone|\n",
      "+----------+-----------------+--------------------+--------------------+\n",
      "|1106214172|Prometheus Barwis|prometheus.barwis...|      (533) 072-2779|\n",
      "| 527133132|Ashraf Bainbridge|ashraf.bainbridge...|                null|\n",
      "|1290614884|   Alain Hennesey|alain.hennesey@fa...|(942) 208-8460,(8...|\n",
      "|1700818057| Hamed Fingerhuth|hamed.fingerhuth@...|                null|\n",
      "|  17378782|    Annamae Leyte|annamae.leyte@msn...|                null|\n",
      "+----------+-----------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- phone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users = spark.read.csv('data/users.txt',\n",
    "                         header=False,       # use headers or not\n",
    "                         quote='\"',         # char for quotes\n",
    "                         sep=\";\",           # char for separation\n",
    "                         schema=users_schema, # using predefined schema\n",
    "                         inferSchema=False)  # do we infer schema or not ?\n",
    "\n",
    "users.count()\n",
    "users.show(5)\n",
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   3\\. Load an RDD `transactions_rdd` from `data/transactions.txt` using `spark.sparkContext.textFile`. Use `.take(5)` to check the result.\n",
    "   \n",
    "   Use `.map()` to split those csv-like lines, to strip the dollar sign on the second column, and to cast each column to its proper type.\n",
    "   \n",
    "   4\\. Create a schema for this dataset using proper names and types for the columns, using types from the `pyspark.sql.types` module (see lecture). Use that schema to convert `transactions_rdd` into a dataframe `transactions`  and use `.show(5)` and `.printSchema()` to check the result.\n",
    "   \n",
    "   Each row in the `transactions` file has the columns  `user_id, amount_paid, date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(815581247, 144.82, '2015-09-05'),\n",
       " (1534673027, 140.93, '2014-03-11'),\n",
       " (842468364, 104.26, '2014-05-06'),\n",
       " (1720001139, 194.6, '2015-08-24'),\n",
       " (1397891675, 307.72, '2015-09-25')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_rdd = spark.sparkContext.textFile('data/transactions.txt')\\\n",
    "                        .map(lambda s : s.split(';'))\\\n",
    "                        .map(lambda row : (int(row[0]),float(row[1].lstrip(\"$\")),row[2]))\n",
    "\n",
    "transactions_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a schema of your own\n",
    "transactions_schema = StructType( [\n",
    "    StructField('user_id',IntegerType(),True),\n",
    "    StructField('amount_paid',FloatType(),True),\n",
    "    StructField('date',StringType(),True) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+\n",
      "|   user_id|amount_paid|      date|\n",
      "+----------+-----------+----------+\n",
      "| 815581247|     144.82|2015-09-05|\n",
      "|1534673027|     140.93|2014-03-11|\n",
      "| 842468364|     104.26|2014-05-06|\n",
      "|1720001139|      194.6|2015-08-24|\n",
      "|1397891675|     307.72|2015-09-25|\n",
      "+----------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- amount_paid: float (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions = spark.createDataFrame(transactions_rdd, transactions_schema)\n",
    "\n",
    "transactions.count()\n",
    "transactions.show(5)\n",
    "transactions.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Write a sequence of transformations or a SQL query that returns the names and the amount paid for the users with the **top 10** transaction amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+--------------------+--------------------+----------+-----------+----------+\n",
      "|   user_id|             name|               email|               phone|   user_id|amount_paid|      date|\n",
      "+----------+-----------------+--------------------+--------------------+----------+-----------+----------+\n",
      "|1093225999|   Landri Fulshur|landri.fulshur@me...|(898) 198-1781,(6...|1093225999|     999.99|2015-03-04|\n",
      "| 504736332|      Raziel Merk|raziel.merk@faceb...|(275) 456-4661,(7...| 504736332|     999.99|2015-01-10|\n",
      "|1009490315|Leilani Cranstoun|leilani.cranstoun...|                null|1009490315|     999.98|2014-09-05|\n",
      "|1378643543|   Zasia Scrivens|zasia.scrivens@ms...|      (880) 354-8779|1378643543|     999.98|2014-04-04|\n",
      "|  50874512|Samyrah Milbourne|samyrah.milbourne...|                null|  50874512|     999.98|2015-03-07|\n",
      "| 420754422|   Vishwak Farrow|vishwak.farrow@me...|(979) 784-6613,(9...| 420754422|     999.98|2015-11-23|\n",
      "| 740624030|      Ori Horrage|ori.horrage@gmail...|      (587) 512-3379| 740624030|     999.98|2014-06-22|\n",
      "| 197275390|    Kianu Dyneley|kianu.dyneley@gma...|                null| 197275390|     999.99|2014-09-09|\n",
      "| 225990677|    Andrian Waite|andrian.waite@gma...|                null| 225990677|     999.99|2014-07-11|\n",
      "|2141604701|    Veida Hubbard|veida.hubbard@fac...|      (125) 967-5303|2141604701|     999.98|2014-10-18|\n",
      "+----------+-----------------+--------------------+--------------------+----------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.join(transactions.orderBy(col('amount_paid'), ascending=False).limit(10),\n",
    "           transactions.user_id == users.user_id).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+\n",
      "|             name|amount_paid|\n",
      "+-----------------+-----------+\n",
      "|   Landri Fulshur|     999.99|\n",
      "|      Raziel Merk|     999.99|\n",
      "|Leilani Cranstoun|     999.98|\n",
      "|   Zasia Scrivens|     999.98|\n",
      "|Samyrah Milbourne|     999.98|\n",
      "|   Vishwak Farrow|     999.98|\n",
      "|      Ori Horrage|     999.98|\n",
      "|    Kianu Dyneley|     999.99|\n",
      "|    Andrian Waite|     999.99|\n",
      "|    Veida Hubbard|     999.98|\n",
      "+-----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.createOrReplaceTempView('users')\n",
    "transactions.createOrReplaceTempView('transactions')\n",
    "\n",
    "spark.sql(\"\"\"SELECT users.name, top_transactions.amount_paid\n",
    "                FROM (SELECT * FROM transactions ORDER BY amount_paid DESC LIMIT 10) top_transactions\n",
    "                   INNER JOIN users \n",
    "                   ON top_transactions.user_id = users.user_id\n",
    "                \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
