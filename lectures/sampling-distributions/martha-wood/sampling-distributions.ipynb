{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Always make it pretty.\n",
    "plt.style.use('ggplot')\n",
    "font = {'weight': 'bold',\n",
    "        'size':   16}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have some static, fixed data.  Here's an example dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(999)\n",
    "data = stats.norm(0.1, 1.0).rvs(100)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll probably learn more if we actually draw some pictures of this data set.  For a one dimensional data set there are a few options, but a scatter plot is always a good default choice because it\n",
    "\n",
    "  - Shows all the data\n",
    "  - Is easy to interpret\n",
    "  - Doesn't lose any information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_dim_scatterplot(data, ax, jitter=0.2, **options):\n",
    "    ## why jitter? especially for bootstraping later\n",
    "    if jitter:\n",
    "        jitter = np.random.uniform(-jitter, jitter, size=data.shape)\n",
    "    else:\n",
    "        jitter = np.repeat(0.0, len(data))\n",
    "    ax.scatter(data, jitter, **options)\n",
    "    ax.yaxis.set_ticklabels([])\n",
    "    ax.set_ylim([-1, 1])\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 1))\n",
    "one_dim_scatterplot(data, ax, s=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Empirical Distribution Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possibility for one dimensional data visualization is to plot the **empirical distribution function**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emperical_distribution(x, data):\n",
    "    weight = 1.0 / len(data)\n",
    "    count = np.zeros(shape=len(x))\n",
    "    for datum in data:\n",
    "        count = count + np.array(x >= datum)\n",
    "    return weight * count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "x = np.linspace(-3, 3, num=250)\n",
    "ax[0].plot(x, emperical_distribution(x, data), linewidth=2)\n",
    "ax[0].set_ylim(-0.05, 1.05)\n",
    "ax[0].set_xlim(-3, 3)\n",
    "# ax[0].tick_params(axis='both', which='major', labelsize=15)\n",
    "one_dim_scatterplot(data, ax[1], s=25)\n",
    "_ = ax[0].set_title(\"The Empirical Distribution Function of a Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How is the EDF drawn: When does it increase?  How much does it increase each time?  What is it attempting to approximate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will take another path towards understanding samples taken from an unknown population.  Yesterday we fit statistical models to approximate the popuation, today we will study mathematical properties of the population itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central limit theorem is nice, it is a central result in mathematical statistics, and there is no other result in the subjects with the definitive nature of the CLT.\n",
    "\n",
    "On the other hand, it has a huge drawback: **it only works for a single statistic, the sample mean!**  It would be nice to have a general procedure that will let us estimate the variance (or the entire distribution) of **any sample statisic**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generally have one fixed dataset, which we view as a single sample from the population.  **The population is the object that interests us, and the sample is the lens through which we get to view it.**\n",
    "\n",
    "The idea behind the bootstrap is that the **empirical distribution** of the sample should be our **best approximation** to the distribution of the population the sample is drawn from.  We can illustrate this by comapring the emperical distribution functions of samples to the actual population distribution functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def superimpose_pdf_of_fit_model(data, model, ax, x_lower=-3, x_upper=3):\n",
    "#     x = np.linspace(x_lower, x_upper, num=250)\n",
    "#     ax.hist(data, bins=25, normed=True, color=\"black\", alpha=0.4)\n",
    "#     ax.plot(x, model.pdf(x), linewidth=3)\n",
    "    \n",
    "def superimpose_cdf_of_fit_model(data, model, ax, x_lower=-3, x_upper=3):\n",
    "    lwd = 3\n",
    "    x = np.linspace(x_lower, x_upper, num=250)\n",
    "    ax.plot(x, emperical_distribution(x, data),\n",
    "            linewidth=lwd, alpha = .5, label = \"sample\")\n",
    "    ax.plot(x, model.cdf(x), label = \"population\",\n",
    "            linewidth=lwd, linestyle = \"dashed\")\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.legend()\n",
    "\n",
    "def emperical_distribution(x, data):\n",
    "    weight = 1.0 / len(data)\n",
    "    count = np.zeros(shape=len(x))\n",
    "    for datum in data:\n",
    "        count = count + np.array(x >= datum)\n",
    "    return weight * count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(99)\n",
    "population = stats.norm(0.9, 0.6)\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4), sharey=True)\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    sample = population.rvs(50)\n",
    "    superimpose_cdf_of_fit_model(sample, population, ax)\n",
    "fig.suptitle(\"Population vs. Sample CDFs (normal)\")\n",
    "plt.tight_layout(pad = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(99)\n",
    "population = stats.uniform(-2, 2.5)\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4), sharey=True)\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    sample = population.rvs(100)\n",
    "    superimpose_cdf_of_fit_model(sample, population, ax)\n",
    "fig.suptitle(\"Population vs. Sample CDFs (uniform)\", fontsize=20)\n",
    "plt.tight_layout(pad = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that  **since we cannot repeatedly sample from the population, our next best bet is to sample from the sample itself**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap: The Big Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to do this:\n",
    "\n",
    "> Estimate the variance of a sample statistic by repeatedly sampling from the *population*, computing the sample means of these samples, and then computing the variance of the multiple sample means.\n",
    "\n",
    "But we **can't**, because we can **only sample from the population one time**.\n",
    "\n",
    "Instead, we repeatedly sample from our **best approximation to the population distribution**, which is given by the **empirical density function of the sample**.\n",
    "\n",
    "That is, instead we do\n",
    "\n",
    "> Estimate the variance of the sample means by repeatedly sampling from *a distribution approximating the population distribution*, computing the sample means of these samples, and then computing the variance of the multiple sample means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **bootstrap sample** from a dataset is a sample taken with replacement from that dataset whose size is the size of the dataset itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_in_blank_plot(text, ax):\n",
    "    '''make a text box'''\n",
    "    _ = ax.text(0.5, 0.5, text, \n",
    "                horizontalalignment='center',\n",
    "                verticalalignment='center',\n",
    "                fontsize=15)\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     12
    ]
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "fig = plt.subplots(1, 1, figsize=(16, 4))\n",
    "\n",
    "ax = plt.subplot2grid((6, 3), (0, 0), colspan=2) # Number of columns for the axis to span downwards.\n",
    "ax.get_xaxis().set_ticks([])\n",
    "ax.set_xlim(-2.5, 3)\n",
    "one_dim_scatterplot(data, ax, s=15)\n",
    "\n",
    "ax = plt.subplot2grid((6, 3), (0, 2), colspan=1)\n",
    "text_in_blank_plot(\"Original Sample\", ax)\n",
    "\n",
    "## boostrapping 5 times\n",
    "for i in range(0, 5):\n",
    "    bootstrap = np.random.choice(data, size=len(data), replace=True)\n",
    "    ax = plt.subplot2grid((6, 3), (i + 1, 0), colspan=2)\n",
    "    ax.get_xaxis().set_ticks([])\n",
    "    ax.set_xlim(-2.5, 3)\n",
    "    one_dim_scatterplot(bootstrap, ax, s=15, c=\"black\")\n",
    "    ax = plt.subplot2grid((6, 3), (i + 1, 2), colspan=1, sharex = ax)\n",
    "    text_in_blank_plot(\"Bootstrap Sample {}\".format(i+1), ax)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each bootstrap sample has it's **own** sample median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     12
    ]
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "# colspan: Number of columns for the axis to span downwards.\n",
    "ax = plt.subplot2grid((6, 3), (0, 0), colspan=2) \n",
    "ax.get_xaxis().set_ticks([])\n",
    "ax.set_xlim(-2.5, 3)\n",
    "one_dim_scatterplot(data, ax, s=15)\n",
    "\n",
    "ax = plt.subplot2grid((6, 3), (0, 2), colspan=1)\n",
    "text_in_blank_plot(\"Original Sample\", ax)\n",
    "\n",
    "## boostrapping 5 times\n",
    "for i in range(0, 5):\n",
    "    bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "    ax = plt.subplot2grid((6, 3), (i + 1, 0), colspan=2)\n",
    "    ax.get_xaxis().set_ticks([])\n",
    "    ax.set_xlim(-2.5, 3)\n",
    "    one_dim_scatterplot(bootstrap_sample, ax, c=\"black\", s=15)\n",
    "    sample_median = np.median(bootstrap_sample)\n",
    "    ax.scatter([sample_median], 0, c=\"red\", s=50)\n",
    "    ax = plt.subplot2grid((6, 3), (i + 1, 2), colspan=1)\n",
    "    text_in_blank_plot(\"Bootstrap Sample {}\".format(i+1), ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample medians taken from repeated bootstrap samples are then an approximation to the **distribution of the sample medians**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sample_medians(data, n_bootstrap_samples=10**4):\n",
    "    bootstrap_sample_medians = []\n",
    "    for i in range(n_bootstrap_samples):\n",
    "        bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "        bootstrap_sample_medians.append(np.median(bootstrap_sample))\n",
    "    return bootstrap_sample_medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(321)\n",
    "bootstrap_medians = bootstrap_sample_medians(data)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(12, 4))\n",
    "ax.hist(data, bins=25, density=True, color=\"black\", alpha=0.4,\n",
    "        label=\"Sample Data\")\n",
    "ax.hist(bootstrap_medians, bins=25, density=True, color=\"red\", alpha=0.75,\n",
    "        label=\"Bootstrap Sample medians\")\n",
    "ax.legend()\n",
    "# ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "_ = ax.set_title(\"Bootstrap Sample medians (10000 samples)\", fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the bootstrap distribution of the sample meadian to estimate statistics that would otherwise be un-approchable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_of_sample = np.var(data)\n",
    "varaince_of_bootstrap_medians = np.var(bootstrap_medians)\n",
    "\n",
    "print(\"Variance of Sample: {:2.2f}\".format(variance_of_sample))\n",
    "print(\"Variance of Sample medians: {:2.2f}\".format(varaince_of_bootstrap_medians))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals: Capturing Population Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our statement from earlier\n",
    "\n",
    "> Our general interest is in the **population**, the **sample** is just the lens we get to view it through.\n",
    "\n",
    "We have shown that **sample statistics are generally good approximations of properties of the population**, and we have also discovered **methods for approximating the distribution of sample statistics**  such as bootstrapping and the central limit theorem.\n",
    "\n",
    "Together these allow us to address a final question\n",
    "\n",
    "> How good of an approximation of a population parameter is a sample statistic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Bootstrap Confidence Interval for 75-th Percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider estimating a confidence interval of the 75-th percentile of a population.  In this case, the central limit theorem does not allow us to derive a mathematical form of the sampling distribution, instead we can proceed by using bootstrap sampling.\n",
    "\n",
    "Here is the bootstrap procedure for computing a confidence interval for a 75-th percentile\n",
    "\n",
    "  - Draw many bootstrap samples from your main sample, and for each:\n",
    "    - Compute the sample statistic (using the bootstrap sample)\n",
    "  - Gather together all the sample statistics of the various bootstrap samples into a list.\n",
    "  \n",
    "The resulting list can be considered as a sample from the sampling distribution of the statistic.\n",
    "\n",
    "  - Compute the 95% confidence interval by finding the 0.025 and 0.975 percentiles of the resulting list of sample statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(333)\n",
    "bootstrap_sample_75_percentiles = []\n",
    "for i in range(10000):\n",
    "    bootstrap = np.random.choice(data, size=len(data), replace=True)\n",
    "    bootstrap_75_percentile = np.percentile(bootstrap, 75)\n",
    "    bootstrap_sample_75_percentiles.append(bootstrap_75_percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates an approximation the the sampling distribution of the statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(10, 4))\n",
    "ax.hist(bootstrap_sample_75_percentiles, bins=500, density=True, color=\"black\", alpha=0.5)\n",
    "ax.set_title(\"boostrap sample 75 percentiles\", fontsize=20)\n",
    "# ax.tick_params(axis='both', which='major', labelsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a confidence interval by computing the 0.025 and 0.975 percentiles of the resulting sampling distribution approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_endpoint = np.percentile(bootstrap_sample_75_percentiles, 2.5)\n",
    "right_endpoint = np.percentile(bootstrap_sample_75_percentiles, 97.5)\n",
    "\n",
    "print(\"Sample 75'th Percentile: {:2.2f}\".format(np.percentile(data, 75)))\n",
    "print(\"Bootstrap Confidence Interval for Population 75'th Percentile: [{:2.2f}, {:2.2f}]\".format(\n",
    "    left_endpoint, right_endpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Why is this confidence interval not symmetric?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap: The Point\n",
    "\n",
    "The Bootstrap is a tool to **quantify the variation in a statistical estimate**.  It can be used in almost **any** situation.\n",
    "\n",
    "The bootstrap is a giant point in favor of the massive amount of computation all of us has at our disposal in modern day.  Before the computer age, the practice of statistics was tedious and mathematical.  Now we can estimate things earlier generations would **never have dreamed of** by simply putting to work some carefully engeneered slabs of silicon."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
