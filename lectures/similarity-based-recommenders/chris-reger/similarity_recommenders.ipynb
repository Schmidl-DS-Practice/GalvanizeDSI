{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Collaborative Recommenders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* Explain how similarity-based collaborative recommenders differ from content-based recommenders.\n",
    "* Discuss the differences between and relative advantages of item-item and user-user similarity recommenders.\n",
    "* Explain how and why neighborhoods are calculated for similarity recommenders.\n",
    "* Discuss two problems with the evaluation of recommenders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda:  \n",
    " 1. Terminology for recommenders  \n",
    " 2. Data format for collaborative recommenders\n",
    "     Explicit vs Implicit ratings\n",
    " 3. Similarity collaborative recommendations\n",
    "    User-User Method vs Item-Item Method\n",
    " 4. Pros and cons of collaborative filtering (similarity collaborative filters)\n",
    " 5. Issues with evaluation of recommenders  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recap:  \n",
    " - **Content recommenders** only take into account the item features and the given user actions/ratings.   \n",
    " - **Collaborative recommenders** take into account the actions of other users to make recommendation.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative recommenders can be built to give more diverse recommendations there is more vocabulary we need to talk about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative recommenders can be based on:\n",
    "* memory (i.e. past user behavior / ratings)\n",
    "* models - SVD and NMF to discover latent factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminology \n",
    "\n",
    " - **Serendipity**: How surprising are the recommendations? Did you recommend something the user wouldn’t have otherwise seen? (If you ask your best friend for a single book recommendation of a really good book and they say Harry Potter, they maybe kinda blew it (because you already knew that))  \n",
    " - **Personalization**: Populist versus personalized. Popular can seem dumb; too personal can be creepy. And popular doesn’t always work.  \n",
    " - **Diversity**: Did you recommend Harry Potter 1, 2, 3, ...? “Silver Bullet” vs Shotgun. But also want basket approach (beer with those diapers?). Breadth vs Depth. Breadth and Depth?\n",
    " - **Persistence**: Have you recommended this item before?\n",
    " - **Modality**: I usually want Sweet Tomatoes, but tonight I’m in a different modality because it’s date night and my wife doesn’t like Sweet Tomatoes\n",
    " - **Privacy**: You’re generally pretty similar to Moses, and he just bought furry pink handcuffs, do you want some?\n",
    " - **Motivation**: Pure best match? (Medical Treatment) Overall product value? (Pandora) Specific sale/margin? (Amazon) Upsell? (Wells Fargo)\n",
    " - **Trust**: What is the motivation? What data is offered, used? How is it being used? Why am I seeing what I’m seeing?\n",
    " - **Confidence**: How good are the results? How understandable are the mistakes? Harry Potter 7 is an understandable mistake, 50 Hairdos for Terrible People might not be. Confidence over time, especially: building trust first and then branching out. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Collaborative Types of Data\n",
    "\n",
    "Data can be:\n",
    "\n",
    "*   *Explicit*:\n",
    "    -   User provided ratings (1 to 5 stars)\n",
    "    -   User like/non-like\n",
    "*   *Implicit*:\n",
    "    -   Infer user-item relationships from behavior\n",
    "    -   More common\n",
    "    -   Example: buy/not-buy; view/not-view\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<details><summary><font size='3'>\n",
    "    <italics> Q: What are some other ways of capturing implicit data? </italics> \n",
    "    </font>\n",
    "</summary>\n",
    "    \n",
    "<font size='3'>\n",
    " - Time viewed (YouTub, Netflix)    <br/>\n",
    " - Number of times clicked/listened (Pandora) <br/>  \n",
    " - Percentage scrolled (NY Times) <br/>  \n",
    "    <br/>\n",
    "        <br/>\n",
    " One thing to take away is number of times listened to or watched has become a powerful method of not just creating recommendations but also to evaluate a new one.\n",
    "    \n",
    "</details>\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Data\n",
    "\n",
    "Recommender systems are a subclass of information filtering.  The idea is finding methods to filter the huge amount of data/options we have over the internet into what the user is interested in.  With this in mind being able to segment a population into similar groupings to may be useful for recommendations.   \n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "<details><summary><font size='4'>\n",
    "Q: What might be some useful things to know about a user.  What may we have access to? \n",
    "    </font>\n",
    "</summary>\n",
    "    \n",
    "<font size='3'>\n",
    "    <br/>\n",
    "If they signed in we have a user profile and past actions.  At the least we have IP address for location and the use of cookies.  There is also how they ended up at the site (ie google, or another site).\n",
    "    \n",
    "</details>\n",
    "<br/><br/><br/>\n",
    "    \n",
    "We call the matrix of user-item data a **utility matrix**. \n",
    "**The goal of collaborative filtering is to complete this utility matrix in order to make recommendations**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Example:    Explicit utility matrix\n",
    "\n",
    "Example 9.1 in [Mining of Massive Datasets](http://infolab.stanford.edu/~ullman/mmds/book.pdf):\n",
    "\n",
    "| &nbsp;| Item1   | Item2   | Item3   | Item4    | Item5   | Item6   | Item7   |\n",
    "| :---- | :---- | :--   | :--   | :--   | :--   | :--   | :--   |\n",
    "| User1     |  4    | &nbsp;| &nbsp;| 5     | 1     | &nbsp;| &nbsp;|\n",
    "| User2     |  5    | 5     | 4     | &nbsp;| &nbsp;| &nbsp;| &nbsp;|\n",
    "| User3     | &nbsp;| &nbsp;| &nbsp;| 2     | 4     | 5     | &nbsp;|\n",
    "| User4     | &nbsp;| 3     | &nbsp;| 5     | 1     | &nbsp;| 3     |\n",
    "\n",
    "---\n",
    "\n",
    "####  Example:    Implicit utility matrix\n",
    "\n",
    "\n",
    "| &nbsp;| Item1   | Item2   | Item3   | Item4    | Item5   | Item6   | Item7   |\n",
    "| :---- | :---- | :--   | :--   | :--   | :--   | :--   | :--   |\n",
    "| User1     |  1    | &nbsp;| &nbsp;| 1     | 1     | &nbsp;| &nbsp;|\n",
    "| User2    |  1    | 1     | 1     | &nbsp;| &nbsp;| &nbsp;| &nbsp;|\n",
    "| User3     | &nbsp;| &nbsp;| &nbsp;| 1     | 1     | 1     | &nbsp;|\n",
    "| User4     | &nbsp;| 1     | &nbsp;| 1     | 1     | &nbsp;| 1     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction vs Ranking\n",
    "\n",
    "There are 2 possible outcomes when talking about recommenders.  With explicit recommenders there is the goal of **predicting** the rating a user may give a item.  The other outcome is **ranking** based.  That is showing $n$ items the user will want to interact with.  \n",
    "\n",
    "*How would we go about testing these predictions?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Similarity Recommenders\n",
    "<br/>  \n",
    " \n",
    "There are 2 sub-types of similarity recommenders:\n",
    " - User-User Similarity\n",
    "   * Comparing user preferences to other users\n",
    "   * Idea: Similar users give similar ratings to a single product\n",
    "   * Generally a specific user only interacts with a small subset of products, so can get high-variance, low bias estimates\n",
    "   \n",
    "   \n",
    " - Item-Item Similarity\n",
    "   * Comparing items to items\n",
    "   * Idea: A single user will give similar ratings to similar products\n",
    "   * Many users interact with a specific product, so item ratings are robust, so can get low variance, high bias estimates\n",
    "   \n",
    "   \n",
    "\n",
    "| &nbsp;| HP1   | HP2   | HP3   | TW    | SW1   | SW2   | SW3   |\n",
    "| :---- | :---- | :--   | :--   | :--   | :--   | :--   | :--   |\n",
    "| Al     |  4    | &nbsp;| &nbsp;| 5     | 1     | &nbsp;| &nbsp;|\n",
    "| Bob     |  5    | 5     | 4     | &nbsp;| &nbsp;| &nbsp;| &nbsp;|\n",
    "| Cat     | &nbsp;| &nbsp;| &nbsp;| 2     | 4     | 5     | &nbsp;|\n",
    "| Dan     | &nbsp;| 3     | &nbsp;| 5     | 1     | &nbsp;| 3     |\n",
    "\n",
    "\n",
    "\n",
    "When talking about the utility matrix let:\n",
    " - $m$ be number of users\n",
    " - $n$ be the number of items \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Question**: If there are $m$ users and $n$ items, we need to compute the similarity of all pairs; thus the preprocessing time complexity for user-user similarity is $\\mathcal O(m^2n)$ (how so?) and item-item similarity is $\\mathcal O(mn^2)$, with respective space complexity estimates of $\\mathcal O(m^2)$ and $\\mathcal O(n^2)$. Which one is more algorithmicly efficient?\n",
    "\n",
    "Item-Item is more common form of recommender (originally it was user-user but Amazon showed the effectiveness of item-item).  For the rest of the talk I will be using item-item system, to change to user-user you could simply flip the matrix first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Predictions\n",
    "\n",
    "Say user $u$ hasn't rated item $i$.  We want to predict the rating this user would give the item.    \n",
    "\n",
    "\n",
    "Approach:\n",
    "- Get utility matrix (user-item rating matrix)\n",
    "- Get item-item (or user-user) similarity matrix\n",
    "- Based on user's ratings of items and these items' similarities to the predicted item, calculate rating\n",
    "\n",
    "### Similarity\n",
    "\n",
    "$$\n",
    "rating(u,i) = \\frac{ \\sum_{j \\in I_u} similarity(i,j) * r_{u,j} } {\\sum_{j  \\in I_u} similarity(i,j) }\n",
    "$$    \n",
    "   \n",
    "Where:  \n",
    " - $I_u$ = set of items rated by user $u$\n",
    " - $r_{u,j}$ = user $u$'s rating of item $j$\n",
    " - $sim(i, j)$ =  similarity between items i and j\n",
    " \n",
    " \n",
    " *What kind of similarity metrics can be used?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/item_item_example1.png\" alt=\"Item-Item utility matrix\">\n",
    "<img src=\"../images/item_item_example2.png\" alt=\"Item-Item utility matrix\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "<details><summary><font size='4'>\n",
    "Q: Is there something that can be done to speed this up? \n",
    "    </font>\n",
    "</summary>\n",
    "    \n",
    "<font size='3'>\n",
    "    <br/>\n",
    "Should we be calculating a user's rating for items that are not similar?\n",
    "    \n",
    "</details>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Neighborhoods\n",
    "\n",
    "To speed up the calculation we can just look at the $n$ most similar items when calculating the prediction.   \n",
    "\n",
    "Updated approach:\n",
    "- Get utility matrix (user-item rating matrix)\n",
    "- Get item-item (or user-user) similarity matrix\n",
    "- Order user's rated items by similarity\n",
    "- Select the neighborhood (i.e. most similar items)\n",
    "- Based on user's ratings of neighboring items and these items' similarities to the predicted item, calculate rating\n",
    "   \n",
    "$$\n",
    "rating(u,i) = \\frac{ \\sum_{j \\in I_u \\cap N_i} similarity(i,j) * r_{u,j} } {\\sum_{j  \\in I_u \\cap N_i} similarity(i,j) }\n",
    "$$     \n",
    "\n",
    "Where:  \n",
    " - $I_u$ = set of items rated by user $u$\n",
    " - $r_{u,j}$ = user $u$'s rating of item $j$\n",
    " - $N_i$ = $n$ most similar items to $i$   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the example above, how would Cat rate B, using the top 2 most similar items?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Recommend best items\n",
    "\n",
    "Recommend items with highest predicted rating:\n",
    "\n",
    "*   Sort predicted ratings $\\hat{r}_{ui}$\n",
    "*   Optimize by only searching a neighborhood which contains the $n$ items most similar to $i$\n",
    "*   Beware:\n",
    "    -   Consumers like variety\n",
    "    -   Don't recommend every Star Trek film to someone who liked first film\n",
    "    -   Best to offer several different types of item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying a Recommender\n",
    "\n",
    " - Compute the similarity matrix and user/item neighborhoods off line.  \n",
    " - Compute predicted ratings/rankings live\n",
    "\n",
    "What should you think about when you hear neighborhoods? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages and Disadvantages of Similarity-Based Collaborative Filtering\n",
    "\n",
    "### Advantages\n",
    "- Serendipitous recommendations\n",
    "- No domain knowledge / feature extraction necessary\n",
    "\n",
    "### Disadvantages\n",
    "- Cannot predict ratings for new users or new items\n",
    "- Computationally expensive!\n",
    "- Scalability\n",
    "- Sparsity: Too little data on item(s) to make good prediction\n",
    "- Hard to include item features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  The cold-start problem\n",
    "\n",
    "It's difficult to build a recommender without ratings!\n",
    "*   Must also handle new users and new items\n",
    "\n",
    "*   *Cold-start* problem:\n",
    "    -   Need utility matrix to recommend!\n",
    "\n",
    "*   Approaches:\n",
    "    -   Can ask new users to rate items\n",
    "    -   Infer ratings from behavior, e.g., viewing an item\n",
    "    -   Use ensemble of (bad) recommenders until you have enough ratings\n",
    "    -   Use content-based recommender\n",
    "    -   Exploit implicit, tag, and other side data\n",
    "    -   Use `ItemSimilarityModel` until you have enough rating data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a Recommender\n",
    "\n",
    "Evaluation of recommenders is a difficult task with many things to keep in mind.  There is not a **best** method and the methods should be based on the business goal.  There are many things to keep in mind when putting together a evaluation metric and many times these are custom to the problem.  Things to think about:\n",
    "\n",
    " - Given the utility matrix how would split data to evaluate your recommender?  \n",
    " - Can we use the same test train split method?  \n",
    " - What issues may we have splitting temporally?\n",
    " - RMSE and MAE are historically used (Netflix prize): what are the drawbacks?\n",
    " - Is there equal weight in getting low ratings wrong as high?\n",
    " \n",
    " \n",
    "That being said the best way to validate a recommender is A/B test in the real world as usually lift or hit rate are the real business goals.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking Metrics\n",
    "\n",
    "Ranking metrics are useful to test how well a recommender is doing as many times predicting the score a user would give is not important, showing something they will click is.  Below is a method of scoring a implicit recommender where they have number of interactions.  This is originally from [this paper](http://yifanhu.net/PUB/cf.pdf) for a music recommender.\n",
    "\n",
    "$$\n",
    "\\overline{rank} = \\frac{\\sum_{u,i} r^t_{ui} * rank_{ui}}{\\sum_{u,i} r^t_{ui}}\n",
    "$$\n",
    "Where:  \n",
    " - $r^t_{ui}$ is the # of interactions or observations in the test set.\n",
    " - $rank_{ui}$ are the percentile ranking of each item for each user in reverse order.\n",
    "    \n",
    "Here more weight is being placed on order of selecting of the items.  The most used items should be predicted highest and thus have a $rank_{ui}$ close to $0$ while low interaction things should have a high $rank_{ui}$.  Thus means the lower the score the better the recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with recommenders you should be ready to spend significant time deciding the best way to validate your results. Another large part of the success of recommenders is based on UX design and how it is introduced to the user. It has been found that many times the **best** recommender is less well received than other options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    " - Types of Data\n",
    "   * Explicit \n",
    "   * Implicit\n",
    " - Similarity Metrics \n",
    "   * Euclidean\n",
    "   * Pearson\n",
    "   * Cosine Similarity\n",
    "   * Jaccard\n",
    " - What are the steps to an Item-Item collaborative Nearest Neighbor Similarity Recommender?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
