{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning and Model Selection using GridSearchCV\n",
    "\n",
    "### Resources:\n",
    "- [sklearn GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)\n",
    "- [sklearn RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "- [Additional walkthrough on Medium found here](https://medium.com/vickdata/a-simple-guide-to-scikit-learn-pipelines-4ac0d974bdcf)\n",
    "- Credit of this notebook goes to Dhaval Patel from Codebasics. [Video found here](https://www.youtube.com/watch?v=HdlDYng8g9s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "This notebook does NOT show the best or only way to work through this process of Hyperparameter Tuning. This is meant to be a very basic and illustrative example. You should still refer to the sklearn documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A worked example using the sklearn iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load in the sklearn iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['flower'] = iris.target\n",
    "df['flower'] = df['flower'].apply(lambda x: iris.target_names[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. train, test, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use a support vector clasifier (SVC) to fit the data and return the best fit (Don't worry too much about it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel='rbf', C=30, gamma='auto') #randomly initialized parameters\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. depending on the training and test sets, we get a different score, so we need to do a k-fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(svm.SVC(kernel='linear', C=10, gamma='auto'), iris.data, iris.target, cv=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with different hyperparameters \n",
    "# get the average score, but its very manual\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also try a number of for loops but think of how long that would take...\n",
    "\n",
    "Pseduocode:\n",
    "```python\n",
    "# set kernel_lst, c_lst, gamma_lst to be a list of parameters you want to try\n",
    "scores = []\n",
    "for k in kernel_lst:\n",
    "    for c in C_lst:\n",
    "        for g in gamma_lst:\n",
    "            scores.append(cross_val_score(svm.SVC(k, c, g), iris.data, iris.target, cv=5)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instead, Use GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set up the GridSearchCV parameters:\n",
    "- first parameter is the model and any parameters we want to set as static \n",
    "- second parameter is the parameter grid = dictionary where key == parameter, value == list of values to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf=GridSearchCV(svm.SVC(gamma='auto'), {\n",
    "    'C': [1, 10, 20], #these are the \n",
    "    'kernel': ['rbf', 'linear']\n",
    "}, cv=5, return_train_score=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fit the data and get the results. Then show it in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(iris.data, iris.target)\n",
    "clf.cv_results_\n",
    "\n",
    "# cast the results to a pandas dataframe\n",
    "df = pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check out the parameters and mean test scores as a pandas dataframe\n",
    "\n",
    "df[['param_C', 'param_kernel', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the directory of the classifier to see the attibutes and methods\n",
    "dir(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Check the best scores and best parameters using the class attributes.\n",
    "\n",
    "these should match one of the best results from what we see in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch Computation Can be Very Costly\n",
    "\n",
    "1. to deal with having lots of for-loops to test out hyperparameters, you can do RandomSearchCV so sklearn does a random gridsearch and you (the user) pass in how many combinations you want to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rs=RandomizedSearchCV(svm.SVC(gamma='auto'), {\n",
    "    'C': [1, 10, 20], #these are the \n",
    "    'kernel': ['rbf', 'linear']\n",
    "}, \n",
    "                 cv=5, \n",
    "                 return_train_score=False, \n",
    "                 n_iter=2)  # n_iter tells us how many combination we need to try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fit the RandomizedSearch and get the cross validated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.fit(iris.data, iris.target)\n",
    "\n",
    "#pass the results to a dataframe\n",
    "df2 = pd.DataFrame(rs.cv_results_)[['param_C', 'param_kernel', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GridSearch to Select the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm #it's already imported. but let's pretend we're starting from scratch\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define the parameter grid \n",
    "\n",
    "Think of this is a trial and error process\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_params = {\n",
    "    'svm': {\n",
    "        'model' : svm.SVC(gamma='auto'), \n",
    "        'params': {\n",
    "            'C': [1, 10, 20], \n",
    "            'kernel': ['rbf', 'linear']\n",
    "        }\n",
    "    }, \n",
    "    'random_forest': {\n",
    "        'model' : RandomForestClassifier(), \n",
    "        'params': {\n",
    "            'n_estimators': [1, 5, 10]\n",
    "    }\n",
    "},\n",
    "    'logistic_regression': {\n",
    "        'model' : LogisticRegression(solver='liblinear', multi_class='auto'),\n",
    "        'params': {\n",
    "            'C': [1, 5, 10], \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Get the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf=GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(iris.data, iris.target)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Show the model with the best parameters and the best score to choose the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
