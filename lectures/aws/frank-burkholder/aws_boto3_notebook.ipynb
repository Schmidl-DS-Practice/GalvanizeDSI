{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Web Services (AWS)\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- Describe core AWS services & concepts\n",
    "- Configure your laptop to use AWS\n",
    "- Use SSH key to access EC2 instances\n",
    "- Launch & access EC2\n",
    "- Access S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Storage + Execution\n",
    "\n",
    "What are the primary services that Amazon AWS offers?\n",
    "\n",
    "Name | Full Name | Service\n",
    "---|---|---\n",
    "S3 | Simple Storage Service | Storage\n",
    "EC2 | Elastic Compute Cloud | Execution\n",
    "EBS | Elastic Block Store | Storage attached to EC2 instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pop Quiz\n",
    "\n",
    "<details>\n",
    "<summary>Q: I want to store some video files on the web. Which Amazon service should I use?</summary>\n",
    "A: S3\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Q: I just created an iPhone app which needs to store user profiles on the web somewhere. Which Amazon service should I use?</summary>\n",
    "A: S3\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Q: I want to create a web application that uses Javascript in the backend along with a MongoDB database. Which Amazon service should I use?</summary>\n",
    "A: S3 + EC2 + EBS\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3 vs. EBS\n",
    "\n",
    "What is the difference between S3 and EBS? Why would I use one versus the other?\n",
    "\n",
    "Feature | S3 | EBS\n",
    "---|---|---\n",
    "Can be accessed from | Anywhere on the web;<br/>any EC2 instance | Specific availability zone;<br/>EC2 instance attached to it\n",
    "Pricing | Less expensive;<br/>Storage (3¢/GB);<br/>Use (1¢/10,000 requests) | More expensive;<br/>Storage (3¢/GB) [+ IOPS]\n",
    "Latency | Higher | Lower\n",
    "Throughput | Usually more | Usually less\n",
    "Performance | Slightly worse |Slightly better\n",
    "Max volume size | Unlimited | 16 TB\n",
    "Max file size | 5 TB | 16 TB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pop Quiz\n",
    "\n",
    "<details>\n",
    "<summary>Q: What is latency?</summary>\n",
    "A: Latency is the time it takes between making a request and the start of a response.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Q: Which is better?  Higher latency or lower?</summary>\n",
    "A: Lower is better.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leveraging S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buckets and Files\n",
    "\n",
    "What is a bucket?\n",
    "- A bucket is a container for files.\n",
    "- Think of a bucket as a logical grouping of files like a sub-domain.\n",
    "- A bucket can contain an arbitrary number of files.\n",
    "\n",
    "How large can a file in a bucket be?\n",
    "- A file in a bucket can be 5 TB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucket Names\n",
    "\n",
    "What are best practices on naming buckets?\n",
    "- Bucket names must be unique across all of s3.\n",
    "- Bucket names must be at least 3 and no more than 63 characters long.\n",
    "- Bucket names must be a series of one or more labels, separated by a single period. \n",
    "- Bucket names can contain lowercase letters, numbers, and hyphens. \n",
    "- Each label must start and end with a lowercase letter or a number.\n",
    "- Bucket names must _not_ be formatted as an IP address (e.g., 192.168.5.4).\n",
    "\n",
    "What are some examples of valid bucket names?\n",
    "- `myawsbucket`\n",
    "- `my.aws.bucket`\n",
    "- `myawsbucket.1`\n",
    "\n",
    "What are some examples of invalid bucket names? \n",
    "- `.myawsbucket`\n",
    "- `myawsbucket.`\n",
    "- `my..examplebucket`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pop Quiz\n",
    "\n",
    "<details>\n",
    "<summary>Q: Why are these bucket names invalid?</summary>\n",
    "A: Bucket names cannot start or end with a period. And they cannot have a multiple periods next to each other.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python - AWS Integration with boto3   \n",
    "\n",
    "`$ pip install boto3`  \n",
    "\n",
    "http://boto3.readthedocs.io/en/latest/guide/quickstart.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Boto is the Amazon Web Services (AWS) SDK for Python, which allows Python developers to write software that makes use of Amazon services like S3 and EC2. Boto provides an easy to use, object-oriented API as well as low-level direct service access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Credentials\n",
    "\n",
    "Your AWS access keys should be in your ~./bashrc (Linux) or ~/.bash_profile (MacOS)\n",
    "  \n",
    "```\n",
    "# AWS\n",
    "export AWS_ACCESS_KEY_ID=AXXXXXXXXXXXXXXXXXXXXA\n",
    "export AWS_SECRET_ACCESS_KEY=YXXXXXXXXXXXXXXXXXXXXXXXXXXXYY\n",
    "\n",
    "```\n",
    "\n",
    "If you are using the AWS CLI, then `$ aws configure` should have put them in `~/.aws/credentials`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a Connection to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boto 3\n",
    "import boto3\n",
    "boto3_connection = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check contents of existing buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boto 3\n",
    "def print_s3_contents_boto3(connection):\n",
    "    for bucket in connection.buckets.all():\n",
    "        for key in bucket.objects.all():\n",
    "            print(key.key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer.csv\n",
      "hello-remote.txt\n"
     ]
    }
   ],
   "source": [
    "print_s3_contents_boto3(boto3_connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most likely nothing there yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s3.Bucket(name='jessicacurley-terminal-from-boto3')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "username = os.environ['USER']\n",
    "bucket_name = username + \"-terminal-from-boto3\"\n",
    "boto3_connection.create_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Make a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a file (could use an existing file, but make one quick from the command line)\n",
    "!echo 'Hello world from boto3!' > hello-boto.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Upload the file to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "s3_client.upload_file('hello-boto.txt', bucket_name, 'hello-remote.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# did it make it?\n",
    "print_s3_contents_boto3(boto3_connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Download a file from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.download_file(bucket_name, 'hello-remote.txt', 'hello-back-again.txt')\n",
    "print(open('hello-back-again.txt').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Demo how to upload & download a file with subfolders using a script\n",
    "`$ python example_upload_download_image.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Go Forth and Conquer the Individual assignment.\n",
    "Notes below are for reference only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Control Access to a Bucket and its contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, our buckets are private.  But you can set them to be public."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find out...\n",
    "def s3_url(bucket, key):\n",
    "    return 'http://s3.amazonaws.com/{}/{}'.format(bucket, key)\n",
    "\n",
    "print(s3_url(bucket_name, 'hello-remote.txt'))\n",
    "print(\"I can, but the public couldn't.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set so the public could read it, buy changing the Access Control List (ACL)\n",
    "bucket = boto3_connection.Bucket(bucket_name)\n",
    "obj = boto3_connection.Object(bucket_name,'hello-remote.txt')\n",
    "bucket.Acl().put(ACL='public-read')\n",
    "obj.Acl().put(ACL='public-read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try again\n",
    "print(s3_url(bucket_name, 'hello-remote.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More on Access Control\n",
    "\n",
    "Q: I want to access my S3 file from a web browser without giving my access and secret keys. How can I open up access to the file to anyone?\n",
    "- You can set up Access Control Lists (ACLs) at the level of the bucket or at the level of the individual objects in the bucket (folders, files).\n",
    "\n",
    "Q: What are the different ACL policies?\n",
    "\n",
    "ACL Policy | Meaning\n",
    "---|---\n",
    "`private` | No one else besides owner has any access rights.\n",
    "`public-read` | Everyone has read access.\n",
    "`public-read-write` | Everyone has read/write access.\n",
    "`authenticated-read` | Registered Amazon S3 users have read access.\n",
    "\n",
    "Q: What does `read` and `write` mean for buckets and files?\n",
    "- Read access to a file lets you read the file.\n",
    "- Read access to a bucket or folder lets you see the names of the files inside it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pop Quiz\n",
    "\n",
    "<details>\n",
    "<summary>Q: If a bucket is `private` and a file inside it is `public-read` can I view it through a web browser?</summary>\n",
    "A: Yes. Access to the file is only determined by its ACL policy.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Q: If a bucket is `public-read` and a file inside it is `private` can I view the file through a web browser?</summary>\n",
    "A: No, you cannot. However, if you access the URL for the bucket you will see the file listed.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon EC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regions\n",
    "\n",
    "Q: What are *AWS Regions*?\n",
    "- AWS is hosted in different geographic locations worldwide. \n",
    "- For example, there are 4 regions in the US.\n",
    "\n",
    "Q: What are the regions in the US\n",
    "\n",
    "Region | Name | Location \n",
    "---|---|--- \n",
    "us-east-1 | US East | N. Virginia\n",
    "us-east-2 | US East 2 | Ohio\n",
    "us-west-1 | US West | N. California\n",
    "us-west-2 | US West 2 | Oregon\n",
    "\n",
    "Q: How should I choose a region?\n",
    "- N. Virginia or `us-east-1` is the default region for EC2.\n",
    "- Using a region other than N. Virginia requires additional configuration.\n",
    "- If you are not sure choose N. Virginia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Availability Zones\n",
    "\n",
    "Q: What are *AWS Availability Zones*?\n",
    "\n",
    "- Regions are divided into isolated availability zones for fault tolerance.\n",
    "- Availability zones run on physically separate hardware and infrastructure.\n",
    "- They do not share hardware, generators, or cooling equipment. \n",
    "- Availability zones are assigned automatically to your EC2 instances based on your user ID.\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>Q: Is it possible for two separate users to coordinate and land on the same availability zone?</summary>\n",
    "1. Availability zones are assigned automatically by the system.\n",
    "2. It is not possible for two AWS users to coordinate and be hosted on the same availability zone.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to EC2\n",
    "\n",
    "Q: How can I connect to an EC2 instance?\n",
    "- Login to the AWS console.\n",
    "- Navigate: EC2 > Launch Instance > Community AMIs > Search community AMIs > Look for an 'Ubuntu' and 'anaconda3' AMI.\n",
    "- View the instance and get its Public DNS.\n",
    "    - This should look something like `ec2-34-229-96-155.compute-1.amazonaws.com`.\n",
    "- Use this command to connect to it.\n",
    "    - `ssh -i ~/.ssh/keypair.pem user@domain`\n",
    "    - Here is an example:\n",
    "        - `ssh -i ~/.ssh/keypair.pem ubuntu@ec2-34-229-96-155.compute-1.amazonaws.com`\n",
    "- Make sure you replace the Public DNS value below with the value you have for your instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying Files to EC2\n",
    "\n",
    "Q: How can I copy files to the EC2 instance?\n",
    "- To copy a file `myfile.txt` to EC2, use a command like this.\n",
    "    - `scp -i ~/.ssh/keypair.pem myfile.txt user@domain:`\n",
    "- To copy a directory `mydir` recursively to EC2, use a command like this. \n",
    "    - `scp -i ~/.ssh/keypair.pem -r mydir user@domain:`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pop Quiz\n",
    "\n",
    "<details>\n",
    "<summary>Q: When you copy a file to EC2 with `scp` will this show up in S3?</summary>\n",
    "A: No. The file will be stored on the disk on the EC2 instance. It will not be in S3.\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
