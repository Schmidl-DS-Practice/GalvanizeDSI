{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF notebook\n",
    "Show how NMF can determine movie topics based on user ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pd.read_csv('den20_movie_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up data frame\n",
    "movie_df.columns = [col.lower().replace(' ', '_') for col in movie_df.columns]\n",
    "movie_df.fillna(0, inplace = True)\n",
    "movie_df.set_index('name', inplace = True)\n",
    "movie_df.replace({\" \" : 0}, inplace = True) # Who put in a space!\n",
    "movie_df = movie_df.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "movie_df.head()\n",
    "movie_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF for topic analysis: motivation\n",
    "\n",
    "You've seen with PCA and SVD that you can decompose a matrix (in this running example, of users, movies, and their ratings of the movies) into latent topics that help relate groups of movies (or words, or books, or whatever your features are in the matrix). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import svd\n",
    "\n",
    "mat = movie_df.values\n",
    "movies = movie_df.columns\n",
    "names = movie_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SVD\n",
    "U, sigma, VT = svd(mat)\n",
    "\n",
    "# do 3 topics...for now \n",
    "k = 3\n",
    "topics = ['latent_topic_{}'.format(i) for i in range(k)]\n",
    "\n",
    "# Keep top k concepts for comparison\n",
    "U = U[:,:k]\n",
    "sigma = sigma[:k]\n",
    "VT = VT[:k,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pretty\n",
    "U, sigma, VT = (np.around(x,2) for x in (U,sigma,VT))\n",
    "U = pd.DataFrame(U, index = names, columns = topics)\n",
    "VT = pd.DataFrame(VT, index = topics, columns = movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nMatrix U: people-topic')\n",
    "print(U)\n",
    "print('\\nMatrix S: singular values')\n",
    "print(sigma)\n",
    "print('\\nMatrix V: topic-movies')\n",
    "print(VT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems with SVD for topic analysis\n",
    "\n",
    "**Recall:** $M = U S V^T$\n",
    "\n",
    "Values in $U$ and $V^T$ can be negative, which is weird and hard to interpret. For example, suppose a latent feature is the genre 'Sci-fi'. This feature can be positive (makes sense), zero (makes sense), or negative (what does that mean?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try using NMF instead...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "k = 3 # the number of topics\n",
    "\n",
    "nmf = NMF(n_components = k)\n",
    "nmf.fit(mat) # mat = the matrix made by movie_df.values\n",
    "\n",
    "W = nmf.transform(mat) # the n by k matrix\n",
    "H = nmf.components_ # the k by m matrix\n",
    "\n",
    "# Make the matrices pretty DataFrames\n",
    "W = pd.DataFrame(W, index = names, columns = topics)\n",
    "H = pd.DataFrame(H, index = topics, columns = movies)\n",
    "\n",
    "# Round the decimals\n",
    "W,H = (np.around(x,2) for x in (W, H))\n",
    "\n",
    "# this shows the components \n",
    "print(W.head(30), '\\n\\n', H.head(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Reconstruction Error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# stop truncation\n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.nan)\n",
    "# prevent exponential notation\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# original matrix\n",
    "print(\"\\nOriginal matrix\")\n",
    "print(mat)\n",
    "\n",
    "# # svd reconstruction\n",
    "# print(\"\\nSVD reconstruction\")\n",
    "# print('\\n', np.around(np.dot(U, np.diag(sigma)).dot(VT), 2))\n",
    "\n",
    "# # nmf reconstruction\n",
    "print(\"\\nNMF reconstruction\")\n",
    "print('\\n', np.around(W.dot(H), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Interpreting Concepts\n",
    "#### Think of NMF like 'fuzzy clustering' or 'soft clustering'\n",
    "- The concepts are clusters\n",
    "- Each row (document, user, etc...) can belong to more than one concept\n",
    "\n",
    "#### Top Questions:\n",
    "1. What do the concepts (clusters) mean?\n",
    "2. To which concept(s) does each user/document belong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the topics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 movies in topic 0\n",
    "tpic = 0\n",
    "num_movies = 10\n",
    "top_movies = H.iloc[tpic].sort_values(ascending=False).index[:num_movies]\n",
    "top_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 movies in topic 1\n",
    "tpic = 1\n",
    "num_movies = 10\n",
    "top_movies = H.iloc[tpic].sort_values(ascending=False).index[:num_movies]\n",
    "top_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 movies in topic 2\n",
    "tpic = 2\n",
    "num_movies = 10\n",
    "top_movies = H.iloc[tpic].sort_values(ascending=False).index[:num_movies]\n",
    "top_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which users align with concept 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 users for topic 0\n",
    "tpic = 0\n",
    "top_users = W.iloc[:,tpic].sort_values(ascending=False).index[:5]\n",
    "top_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 users for topic 1\n",
    "tpic = 1\n",
    "top_users = W.iloc[:,tpic].sort_values(ascending=False).index[:5]\n",
    "top_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 users for topic 2\n",
    "tpic = 2\n",
    "top_users = W.iloc[:,tpic].sort_values(ascending=False).index[:5]\n",
    "top_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What concepts does do I align with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to fill in your name and check it out for yourself \n",
    "W.loc['Jess Curley']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the movies associated with the latent topic I align most with  \n",
    "H.loc['latent_topic_1'].sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are all the movies in each topic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of movies in each concept\n",
    "thresh = .6  # movie is included if at least 50% of max weight\n",
    "for g in range(k):\n",
    "    all_movies = H.iloc[g,:]\n",
    "    included = H.columns[all_movies >= (thresh * all_movies.max())]\n",
    "    print(\"\\nTopic %i contains: %s\" % (g, ', '.join(included)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which users are associated with each topic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users in each concept\n",
    "thresh = .3  # movie is included if at least 30% of max weight\n",
    "for g in range(k):\n",
    "    all_users = W.iloc[:,g]\n",
    "    included = W.index[all_users >= (thresh * all_users.max())]\n",
    "    print(\"\\nTopic {} contains: {}\".format(g, ', '.join(included)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Choosing number of (latent) topics by looking at reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute NMF\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "def fit_nmf(k):\n",
    "    nmf = NMF(n_components=k)\n",
    "    nmf.fit(mat)\n",
    "    W = nmf.transform(mat);\n",
    "    H = nmf.components_;\n",
    "    return nmf.reconstruction_err_\n",
    "\n",
    "error = [fit_nmf(i) for i in range(1,10)]\n",
    "plt.plot(range(1,10), error)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Reconstruction Error')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some other stuff you may find helpful with your assignment...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2], [-3, 4]])\n",
    "b = np.array([7, -9])\n",
    "\n",
    "print(np.linalg.solve(A, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squares Solver\n",
    "\n",
    "What if we have an overdetermined system of linear equations? E.g.\n",
    "\n",
    "$$ \\begin{bmatrix} 1 & 2 \\\\ -3 & 4 \\\\ 1 & -4 \\end{bmatrix} \\left[ \\begin{array}{c} x_1 \\\\ x_2 \\end{array} \\right] = \\left[ \\begin{array}{cc} 7 \\\\ -9 \\\\ 17 \\end{array} \\right] $$\n",
    "\n",
    "An exact solution is not guaranteed, so we must do something else. Least Squares dictates that we find the $x$ that minimizes the residual sum of squares (RSS).\n",
    "\n",
    "(Note: This is the solver we use when doing Linear Regression!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2], [-3, 4], [1, -4]])\n",
    "b = np.array([7, -9, 17])\n",
    "\n",
    "print(np.linalg.lstsq(A, b)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.clip(min=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-negative Least Squares Solver\n",
    "\n",
    "What if you want to constrain the solution to be non-negative? (Doing such a thing will be important to us today.)\n",
    "\n",
    "We have optomizers for that too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import nnls\n",
    "\n",
    "A = np.array([[1, 2], [-3, 4], [1, -4]])\n",
    "b = np.array([7, -9, 17])\n",
    "\n",
    "print(nnls(A, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "- [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html)\n",
    "- When it's on L2 normalized data, it's the same as calling ```linear_kernel```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
