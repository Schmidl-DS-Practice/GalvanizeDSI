{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization and Gradient Descent Lecture\n",
    "\n",
    "F. Burkholder (credit T. Heilman and A. Richards) with edits by Jessica Curley "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives GO HERE\n",
    "- Review supervised learning topics\n",
    "- Introduce optimization methods \n",
    "- Learn algorithms to implement the Gradient Descent Algorithm and understand different convergent criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review \n",
    "- What is supervised learning?\n",
    "- Name two examples of supervised learning we've learned so far\n",
    "- How do we interpret the coefficients of linear regression? Of logistic regression?\n",
    "- What is a cost function associated with linear regression?\n",
    "- What are two types of regularized regression?\n",
    "- How does each type of regularization handle the coefficients for highly correlated features?\n",
    "\n",
    "### Connection and Motivation\n",
    "Name a function you are trying to optimize with **logistic regression**. Is this something we want to maximize or minimize?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Gradient Descent?\n",
    "**Gradient Descent is not a machine learning model** - it's a way of updating the coefficients of a model, given true and predicted target values (from the model that uses these coefficients), and a **cost function** that quantifies how different the the predicted and true values are across the training data.\n",
    "\n",
    "Gradient Descent is one way of performing [mathematical optimization.](https://en.wikipedia.org/wiki/Mathematical_optimization)\n",
    "\n",
    "### Why Do We Care?\n",
    "The point of this lecture is expose you to what's happening behind the scenes when you are calling `.fit` on some of sklearn's machine learning models to determine model coefficients (a.k.a. $\\beta$, $\\theta$, parameters, weights)  \n",
    "\n",
    "This same process also helps determine weights in a neural network - so we will revisit this topic when talk neural nets.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Terminology\n",
    "- Cost function: $ J(\\theta) $\n",
    "- Likelihood function: $ L(\\theta) $\n",
    "- Hypothesis function (the function that predicts $y$ from $x$): $ h_\\theta(x_i)$    \n",
    "- Parameters / coefficients / weights : $\\theta$ or $\\beta$ or *w*\n",
    "- Learning rate $\\alpha$ or $\\lambda$\n",
    "\n",
    "As usual, you will encounter lots of different terms and symbols to represent the same things regarding gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "Mathematical optimization includes finding \"best available\" values of some **objective function** given a defined domain (or input).\n",
    "\n",
    "Example \"real world\" objective functions:\n",
    "* The time spent on preparations before leaving your house so that you can arrive at work on time\n",
    "* Deciding what to do now so that you can retire early\n",
    "* Finding the maximum or minimum of some mathematical function\n",
    "\n",
    "In an optimization problem you decide whether you are looking for the objective function's **maximum** or **minimum**. \n",
    "\n",
    "\n",
    "## Optimization in machine learning\n",
    "\n",
    "In [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning) our task is to choose a model, including its coefficients, that will train on existing data and then perform well on unseen data.\n",
    "\n",
    "Here are two examples of objective functions in machine learning:\n",
    "\n",
    "### Linear Regression\n",
    "\n",
    "- Objective function to **minimize** = MSE (this is also known as the cost function here)\n",
    "\n",
    "Find coefficients $\\theta$ that **minimize** the cost function (mean squared error or mean squared residual)\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{N}\\sum_{i=1}^N (y_i - h_\\theta(x_i))^2 $$  \n",
    "\n",
    "$h_\\theta(x)$ are the predictions of the model in this case, otherwise known as $\\hat{y}$ or \"y-hat\"\n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "- Objective function to **maximize** is the log likelihood \n",
    "\n",
    "In the case of binary classification (label is 0 or 1), find coefficients $\\theta$ that **maximize** the likelihood of classifying the true values correctly. We want to maximize the *true positive rate* or *sensitivity*\n",
    "\n",
    "$$  L(\\theta) = \\sum_{i=1}^N (y_i \\ln h_\\theta (x_i) + (1- y_i)\\ln(1- (h_\\theta (x_i))) $$\n",
    "\n",
    "Why the **maximum**?  Let's review what the natural logarithm looks like for values < 1:   [interactive chart](https://www.google.com/search?client=ubuntu&channel=fs&q=graph+of+natural+logarithm&ie=utf-8&oe=utf-8)\n",
    "\n",
    "Note that $h_\\theta(x)$ are the probability predictions of the model, all ranging from 0 to 1.  A threshold is used with these probabilities to make the prediction $\\hat{y}$.  \n",
    "\n",
    "Let's see how this loss function behaves on 2 datapoints when given a bad model (where the coefficients give bad predictions and a large loss) and a better model (where the coefficients give better prediction and a lower loss).  \n",
    "\n",
    "Recall: $y_i$ is the true value of the target ($i$ for the *ith* row), and $h_\\theta (x_i)$ is the probability of $x_i$ being in the positive class (1) given the features $x_i$ in a logistic regression model of the form:\n",
    "\n",
    "$$\\ln \\left( \\frac{h_\\theta (x)}{1 - h_\\theta (x)} \\right) = \\beta_0 + \\beta_1 \\cdot X_1 + \\beta_2 \\cdot X_2 + ... \\beta_p \\cdot X_p$$\n",
    "\n",
    "\n",
    "Model A: The \"worse\" model. Note the probabilities of being in the positive class $h_\\theta (x_i)$ given the true value ($y_i$=1) are pretty bad.\n",
    "\n",
    "|$$y_i$$   |  $$h_\\theta (x_i)$$  |$$y_i \\ln h_\\theta (x_i)$$ | $$(1- y_i)\\ln(1- h_\\theta (x_i))$$ |$$L(\\theta)$$ |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|0  |0.9 |  0 | -2.3  | -2.3  |\n",
    "|1  |0.2 | -1.6 | 0   | -1.6  |\n",
    "|   |    |      |     | -3.9  |  \n",
    "\n",
    "Model B: A \"better\" model. It has different coefficients than Model A and better probabilites \n",
    "\n",
    "|$$y_i$$   |  $$h_\\theta (x_i)$$  |$$y_i \\ln h_\\theta (x_i)$$ | $$(1- y_i)\\ln(1- h_\\theta (x_i))$$ |$$L(\\theta)$$ |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|0  |0.2 |  0 | -0.2  | -0.2  |\n",
    "|1  |0.9 | -0.1 | 0   | -0.1  |\n",
    "|   |    |      |     | -0.3  |  \n",
    "\n",
    "Note that the cost or loss is \"less\" (in this case, maximized) for the model with better coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't always get the best coefficients by solving for the derivative of the objective function our model. Instead, we can use another process that also uses calculus to find the coefficients ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent - A Way to Find the Coefficients\n",
    "\n",
    "[Gradient descent](https://en.wikipedia.org/wiki/Gradient_descent) is a first-order iterative optimization algorithm for finding the minimum of a function.\n",
    "\n",
    "To find a local minimum, one takes steps proportional to the negative of the gradient (or its approximation) of the function at the current point.\n",
    "\n",
    "$$ \\beta_{new} = \\beta_{old} - \\alpha \\cdot \\frac{\\nabla J}{\\partial \\beta}$$\n",
    "\n",
    "$ \\beta_{new} $ is the new estimate of the model coefficients  \n",
    "$ \\beta_{old} $ is the old estimate of the model coefficients  \n",
    "$ \\alpha $ is the learning rate, the tunable parameter that adjusts how much of a step is taken in the direction of the gradient  \n",
    "$ \\frac{\\nabla J}{\\partial \\beta} $ is the gradient, a measure of how much the cost function is increasing with respect to each of the coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/gradient_desc_img.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent in one dimension\n",
    "\n",
    "Let's start with a simplified example, a cost function of $J(x) = 3x^2$  \n",
    "\n",
    "$J$ is the cost, $x$ is the feature/coefficient/parameter that we are trying to update to minimize $J$. \n",
    "\n",
    "Gradient descent requires: \n",
    "* A cost function, $J$\n",
    "* The gradient of the cost function, in this case $ \\frac{\\nabla J}{\\partial x} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_func(x):\n",
    "    return 3*x**2\n",
    "\n",
    "def grad_cost_func(x):\n",
    "    return 6*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this function is differentiable, we know from calculus that we can find the minimum of this function at x = 0. \n",
    "\n",
    "For demonstation purposes, we pretend that we don't know this, and we will start with a guess of x = 5 for the minimum.\n",
    "\n",
    "Let's plot this, for a visual..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping our guesses in a list for reasons that will become clear later....\n",
    "guesses = [5]\n",
    "\n",
    "def plot_cost(x_guess):\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    ax = fig.add_subplot(111) \n",
    "    x = np.linspace(-6, 6)\n",
    "    y = cost_func(x)\n",
    "    ax.plot(x, y)\n",
    "    y_guess = [cost_func(xg) for xg in x_guess]\n",
    "    ax.plot(x_guess, y_guess, 'ro')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('J')\n",
    "    \n",
    "    labels = ['step {}'.format(i) for i in range(len(x_guess))]\n",
    "    for label, x, y in zip(labels, x_guess, y_guess):\n",
    "        plt.annotate(\n",
    "            label,\n",
    "            xy=(x, y), xytext=(-20, 20),\n",
    "            textcoords='offset points', ha='right', va='bottom',\n",
    "            bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "            arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "   \n",
    "plot_cost(guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this one-dimensional case, we can visually inspect and see that we are pretty far from the minimum! \n",
    "\n",
    "Let's compute the gradient at this point to update our \"guess\" for $x$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall grad_cost_funcion in this case is 6x, or the derivative of the cost functoin \n",
    "grad = grad_cost_func(guesses[-1])\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient is huge at our guess! (Remember, this is really just the derivative of the cost function at $x=5$). If we simply adjusted by that amount, we would overshoot the minimum by far! This is why we use the learning rate $\\alpha$ or $\\lambda$ to adjust our guess by small steps. Let's try a learning rate of .05, so we don't go too far. Since we are doing gradient DESCENT, we should subtract the gradient from our guess. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .05 # sometimes referred to as alpha or lambda\n",
    "\n",
    "guess_update = guesses[-1] - learning_rate*grad\n",
    "# let's keep our guesses in a list...\n",
    "guesses.append(guess_update)\n",
    "\n",
    "print(guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot including our new guess..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cost(guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot closer. Let's do this three more times and see where we land..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    grad = grad_cost_func(guesses[-1])\n",
    "    guess_update = guesses[-1] - learning_rate*grad\n",
    "    guesses.append(guess_update)\n",
    "\n",
    "plot_cost(guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that as we get closer to the minimum, the gradient gets smaller and so the guesses step more slowly. This is a good thing - a natural property that makes it harder for us to overshoot!\n",
    "\n",
    "Let's see if 5 more times does the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    grad = grad_cost_func(guesses[-1])\n",
    "    guess_update = guesses[-1] - learning_rate*grad\n",
    "    guesses.append(guess_update)\n",
    "\n",
    "plot_cost(guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks pretty close, let's inspect the list to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#\\tguess\")\n",
    "for i, guess in enumerate(guesses,1):\n",
    "    print(\"{0}\\t{1:0.3f}\".format(i, guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Didn't quite get to the minimum, but with more steps it would."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a simple example where there was only one coefficient to find (there was just one feature).  For most machine learning models, there are multiple features and therefore coefficients to find for each feature.\n",
    "\n",
    "In this case you take a multi-dimensional derivative called the **gradient**.\n",
    "\n",
    "##  Gradient Formula\n",
    "* The gradient is the multivariate analogue (dealing with multiple independent variables) of the derivative. \n",
    "\n",
    "$$ \\nabla f = \\sum_{i=1}^P\\frac{\\partial f}{\\partial x_i} \\vec{e_i}$$\n",
    "\n",
    "Where:  \n",
    "$ \\nabla f$ is the gradient of function $f$  \n",
    "\n",
    "$ \\sum_{i=1}^P$ is the sum over all the predictors (columns) $P$  \n",
    "\n",
    "$ \\frac{\\partial f}{\\partial x_i}$ is the partial derivative of $f$ with respect to predictor $x_i$  \n",
    "\n",
    "$ e_i$ indicates in the direction of the predictor $x_i$\n",
    "\n",
    "Simple example:  Say there were columns $x$, $y$, and $z$ in our X (feature) array, \n",
    "defined to go in directions $\\vec{i}, \\vec{j}, \\vec{k}$.  \n",
    "So $$ \\nabla f = \\frac{\\partial f}{\\partial x} \\vec{i} + \\frac{\\partial f}{\\partial y} \\vec{j}+ \\frac{\\partial f}{\\partial z} \\vec{k}$$\n",
    "\n",
    "Say $$ f(x,y,z) = 2x + 3y^{2} - sin(3z) $$\n",
    "\n",
    "The gradient is:  \n",
    "\n",
    "$$ \\nabla f = 2\\vec{i} + 6y\\vec{j} - 3cos(3z)\\vec{k} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Flavors of Gradient Descent\n",
    "- **Batch gradient descent** - computes the gradient of the cost function with respect to $\\theta$ for the entire dataset \n",
    "    -  accumulates the gradient for all rows of data first, and then make an update.\n",
    "- **Mini-batch gradient descent** - performs an update for every mini-batch of training examples\n",
    "    - the typical algorithm for neural network training\n",
    "    - choosing a learning rate can be tough\n",
    "- **Stochastic gradient descent (SGD)** - performs gradient descent for each training example in x along with its corresponding y\n",
    "    - updates are performed with each training example in $x$\n",
    "    - in practice converges faster than batch gd\n",
    "    - Here is the pseudocode, where n is the number of training examples:\n",
    "    ```python\n",
    "    Randomly shuffle examples in the training set.\n",
    "    Repeat until step size is sufficiently small:\n",
    "        for i = 1, 2, ... n:\n",
    "            β <- β - α * gradient for x_i\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Morning Assignment Preview\n",
    "\n",
    "In your assignment today you'll be working through the gradient descent algorithm for logistic regression.  \n",
    "\n",
    "In this notebook we'll work through an example using linear regression.\n",
    "\n",
    "### First, recall the objective functions\n",
    "\n",
    "#### Linear Regression\n",
    "\n",
    "We want to find coefficients $\\theta$ that *minimize* the mean squared residual:\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{N}\\sum_{i=1}^N (y_i - h_\\theta(x_i))^2 $$\n",
    "\n",
    "#### Logistic Regression\n",
    "\n",
    "We want to find coefficients $\\theta$ that *maximize* the likelihood of the classifying the true values correctly.\n",
    "\n",
    "$$  L(\\theta) = \\sum_{i=1}^N (y_i \\ln h_\\theta (x_i) + (1- y_i)\\ln(1- (h_\\theta (x_i))) $$\n",
    "\n",
    "$ h_\\theta (x_i) $ is the predicted probability of the positive class.\n",
    "\n",
    "To use gradient **descent** we would like to find a minimum instead of a maximum.  So we multiply the maximum likelihood by -1 to change the objective function in to a cost function.\n",
    "\n",
    "$$  J(\\theta) = -\\sum_{i=1}^N (y_i \\ln h_\\theta (x_i) + (1- y_i)\\ln(1- (h_\\theta (x_i))) $$\n",
    "\n",
    "In this form, this is equation is the [binary cross-entropy loss function](https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a).  When it's extrapolated to more than two classes it's simply called [categorical cross entropy](https://machinelearningmastery.com/cross-entropy-for-machine-learning/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Using Gradient Descent Demo\n",
    "First, instantiate a small \"dataset\" X, with 2 features and 10 rows, and **true** beta coefficients (that gradient descent will determine later in the notebook). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) # set random seed\n",
    "nrows = 10\n",
    "const = np.ones((nrows, 1))\n",
    "x1 = np.random.random((nrows, 1)) # nrows number of random floats \n",
    "X = np.hstack([const, x1]) # stack arrays horizontally, or column-wise \n",
    "\n",
    "# define true betas that will be used to calculate y\n",
    "# the goal will be to converge on the true betas using X, y, and gradient descent\n",
    "true_betas = np.array([3, 4]).reshape(-1, 1) # turns it into a column vector \n",
    "print(\"The betas (or weights, or theta in cost functions above) gradient descent will try to find are:\")\n",
    "print(true_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically we know our Xs and $y$s, but are actually trying to solve for the best values of beta. In this example the true beta values are used calculate $y$, and then X and $y$ are used in gradient descent to try to determine what the beta values were.\n",
    "\n",
    "**But don't we already know the correct answer for our coefficients?** Yes- this is just a good way to practice our algorithm by checking it against the correct answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.dot(X,true_betas).reshape(-1, 1) # keep this as a column vector so linear algebra goes smoothly\n",
    "print(\"X array:\")\n",
    "print(np.around(X,2))\n",
    "print(\"\\ny array:\")\n",
    "print(np.around(y,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that np.around did not change the values in the arrays\n",
    "# It just made it nice to display\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice\n",
    "\n",
    "### Steps for Gradient Descent\n",
    "\n",
    "**1. Compute gradient of the cost function.**  \n",
    "Compute the gradient (derivative) of this below. You may find it helpful to first think of it as just one row of data.\n",
    "\n",
    "$$ J_i(\\beta) = \\frac{1}{2}((y_i - x_i \\cdot \\beta))^2 $$\n",
    "where  \n",
    "\n",
    "$ y_i $ is the ith y value (a scalar)  \n",
    "$ x_i $ is a row vector of two values in this case (X has two columns): [$x_{i,0}$, $x_{i,1}$]  \n",
    "$ \\beta $ is a column vector of the coefficents: $[\\beta_0, \\beta_1]^T$  \n",
    "$ x_i \\cdot \\beta $ is the dot product of these two vectors, yielding a scalar\n",
    "\n",
    "\n",
    "Work it out on your own..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_one_coefficient_one_row(y_i, x_i, beta_guess, coeff_index):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_i: one y value that is the target of the row x_i\n",
    "    x_i: one row of X\n",
    "    beta_guess: guess values for the 2 coefficients (2 row, 1 column vector)\n",
    "    coeff_index: index (0 or 1) corresponding to which coefficient gradient applies to\n",
    "    \n",
    "    Returns:\n",
    "    a one value non-dimensional array\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>\n",
    "Click here for solution...\n",
    "</summary>\n",
    "```\n",
    "def gradient_one_coefficient_one_row(y_i, x_i, beta_guess, coeff_index):\n",
    "    return -1 * x_i[coeff_index] * (y_i - np.dot(x_i, beta_guess))\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guess betas\n",
    "beta_guess = np.array([1, 1]).reshape(-1, 1)\n",
    "\n",
    "## try it for one row of data\n",
    "row = 1\n",
    "x_i = X[row]\n",
    "y_i = y[row]\n",
    "\n",
    "grad_Beta0 = gradient_one_coefficient_one_row(y_i, x_i, beta_guess, 0)\n",
    "grad_Beta1 = gradient_one_coefficient_one_row(y_i, x_i, beta_guess, 1)\n",
    "print(\"Gradient of cost function wrt Beta0: \", grad_Beta0)\n",
    "print(\"Gradient of cost function wrt Beta1: \", grad_Beta1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's leverage numpy to calculate the gradients for both coefficients for all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients_coefficients(y, X, beta_guess):\n",
    "    return -1 * X * (y - np.dot(X, beta_guess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_guess = np.array([1, 1]).reshape(-1, 1)\n",
    "\n",
    "gradients = gradients_coefficients(y, X, beta_guess)\n",
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **batch** gradient descent, we're going to accumulate the gradient for all rows of data first, and then make an update.  So we don't care about the gradient for each row - rather the accumulated gradient across all rows.  As each accumulated gradient will be applied to each coefficient, we want to return it as the same shape as the coefficients (a column vector -- note the .reshape(-1, 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients_coefficients_accumulated(y, X, beta_guess):\n",
    "    gradients = -1 * X * (y - np.dot(X, beta_guess))\n",
    "    return gradients.sum(axis=0).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_guess = np.array([1, 1]).reshape(-1, 1)\n",
    "\n",
    "gradients_accum = gradients_coefficients_accumulated(y, X, beta_guess)\n",
    "gradients_accum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, check out this serious numpy magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_grad_func(X, beta_guess, y):\n",
    "    return np.dot(X.T, np.dot(X, beta_guess)-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_guess = np.array([1, 1]).reshape(-1, 1)\n",
    "\n",
    "gradients_accum = mse_grad_func(X, beta_guess, y)\n",
    "gradients_accum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Adjust weights/parameters by the gradient of the cost function scaled by the learning rate\n",
    "Update the betas given the gradient of the cost function that was just computed, scaled by the learning rate. This is gradient DESCENT, so we should subtract our update. \n",
    "\n",
    "Write a function that performs a parameter update and returns updated parameters (This is very simple - should be a one liner, use numpy. DO NOT OVERTHINK THIS!). Since our problem is simple, the default learning rate is (relatively) high at 0.02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paramater_update(betas, grad, lr=0.02):\n",
    "    return betas - lr * grad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>\n",
    "Click here for solution...\n",
    "</summary>\n",
    "```\n",
    "def paramater_update(betas, grad, lr=0.02):\n",
    "    return betas - lr * grad\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Compute objective function, a.k.a the cost function**  \n",
    "We've done this. We are doing a linear regression, so we will use the mean squared error cost function. \n",
    "$$ J(\\theta) = \\frac{1}{N}\\sum_{i=1}^N (y_i - h_\\theta(x_i))^2 $$\n",
    "\n",
    "**4. Check for convergence**  \n",
    "More later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "**Using the gradient and the parameter update functions, you can perform simple gradient descent.**  \n",
    "Start with guesses for beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_guess = np.ones((2,1))\n",
    "beta_guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the iteration count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below as many times as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i += 1\n",
    "print('Iteration {}'.format(i))\n",
    "grad = mse_grad_func(X, beta_guess, y)\n",
    "print('The gradient is: {0:0.2f}, {1:0.2f}'.format(grad[0][0], grad[1][0]))\n",
    "beta_guess = paramater_update(beta_guess, grad)\n",
    "print('New values of beta: {0:0.2f}, {1:0.2f}'.format(beta_guess[0][0], beta_guess[1][0]))\n",
    "print('  Recall true beta: {0:0.2f}, {1:0.2f}'.format(true_betas[0][0], true_betas[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put it all together to implement simple gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_gradient_descent(X, y, beta_guess = np.ones((2,1)), lr = .02, max_iter = 10): \n",
    "    for _ in range(max_iter):\n",
    "        grad = mse_grad_func(X, beta_guess, y)\n",
    "        beta_guess = paramater_update(beta_guess, grad, lr)\n",
    "    return beta_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does it find the right betas?\n",
    "betas = simple_gradient_descent(X, y, max_iter = 1000)\n",
    "print(\"Calculated betas: {}\".format(np.around(betas.ravel(), decimals = 2)))\n",
    "print(\"      True betas: {}\".format(np.around(true_betas.ravel(), decimals = 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent Convergence Criterion\n",
    "We did the simplest case of convergence criteria, a set number of iterations. In practice, you would want to use a more sophisticated convergence criterion - i.e. stopping iterations when your result stops significantly improving.\n",
    "\n",
    "We are updating the ```simple_gradient_descent```function from above into the second block below, but improved it by adding the following stopping criteria in addition to maximum iterations. Feel free to adjust the default paramaters if you don't like the results.\n",
    "\n",
    "* Change in cost function $ (cost_{old} - cost_{new}) / cost_{old} < \\epsilon $\n",
    "\n",
    "The stopping criteria requires the cost to be calculated, so we will use the ```cost_function``` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X, y, beta_guess):\n",
    "    return 1/X.shape[0] * np.sum((y - np.dot(X, beta_guess))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_with_conv(X, y, beta_guess = np.ones((2,1)), lr = .02,\n",
    "                               max_iter = 10000, epsilon = 0.01): \n",
    "    cost_array = []\n",
    "    for i in range(max_iter):\n",
    "        cost_new = cost_function(X, y, beta_guess)\n",
    "        cost_array.append(cost_new)\n",
    "        if i > 2:\n",
    "            cost_old = cost_array[-2]\n",
    "            if abs(cost_old - cost_new)/cost_old < epsilon:\n",
    "                print('Convergence met at iteration {0}.'.format(i))\n",
    "                break\n",
    "        grad = mse_grad_func(X, beta_guess, y)\n",
    "        beta_guess = paramater_update(beta_guess, grad, lr)\n",
    "    return beta_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = gradient_descent_with_conv(X, y, max_iter=10000, epsilon = 0.01)  # you may need to play with the learning rate, max_iter, and epsilon\n",
    "print(\"Calculated betas: {}\".format(np.around(betas.ravel(), decimals = 2)))\n",
    "print(\"      True betas: {}\".format(np.around(true_betas.ravel(), decimals = 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. More detailed look into [other gradient descent optimization algorithms](https://ruder.io/optimizing-gradient-descent/index.html#batchgradientdescent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. A Visualization of a 2D Gradient Descent\n",
    "![gradient1d](images/gradientdescent_2d.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Another visualization of 3D Gradient Descent:\n",
    "![grad_desc_gif](images/gradient_descent.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
