# Decision Trees

Decision trees are a recursive divide and conquer algorithm. They are a non-linear, non-parametric discriminative supervised classification algorithm.  There are a few names of decision tree algorithms you may have heard of (ID3, C4.5, CART, etc.) and each is a different specification of a decision tree model.  You can read about them [here](http://stackoverflow.com/questions/9979461/different-decision-tree-algorithms-with-comparison-of-complexity-or-performance) and [here](http://scikit-learn.org/stable/modules/tree.html#tree-algorithms-id3-c4-5-c5-0-and-cart).

### Goals

* Differentiate between parametric and Non-parametric models
* Implement the CART algorithm
* Calcluate Gini impurity, entropy, and information gain, understand their roles in decision trees


#### Decision Trees

* [Applied Data Science](http://columbia-applied-data-science.github.io/appdatasci.pdf): Chapter 9.4 (p. 100 - p. 104)
* Machine Learning in Action: Chapter 3 ([ID3](http://en.wikipedia.org/wiki/ID3_algorithm))
* [scikit-learn docs: Decision Trees](http://scikit-learn.org/stable/modules/tree.html)


